{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clayton Cohn<br>\n",
    "May 20, 2020<br>\n",
    "DSC 478<br>\n",
    "Prof. Mobasher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"/Users/claytoncohn/Dropbox/New/DePaul/DSC478/data/segmentation_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will experiment with Principal Component Analysis as a dimensionality reduction approach to assist in clustering high-dimensional data. \n",
    "\n",
    "You will also experiment with item-based recommendation for a joke recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. PCA for Reduced Dimensionality in Clustering [Dataset: segmentation_data.zip]__\n",
    "\n",
    "For this problem you will use an image segmentation data set for clustering. \n",
    "\n",
    "You will experiment with using PCA as an approach to reduce dimensionality and noise in the data. \n",
    "\n",
    "You will compare the results of clustering the data with and without PCA using the provided image class assignments as the ground truth. \n",
    "\n",
    "The data set is divided into three files. The file \"segmentation_data.txt\" contains data about images with each line corresponding to one image. \n",
    "\n",
    "Each image is represented by 19 features (these are the columns in the data and correspond to the feature names in the file \"segmentation_names.txt\". \n",
    "\n",
    "The file \"segmentation_classes.txt\" contains the class labels (the type of image) and a numeric class label for each of the corresponding images in the data file. \n",
    "\n",
    "After clustering the image data, you will use the class labels to measure completeness and homogeneity of the generated clusters. \n",
    "\n",
    "The data set used in this problem is based on the Image Segmentation data set at the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Load in the image data matrix (with rows as images and columns as features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1.186342</td>\n",
       "      <td>12.925926</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>-6.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>17.222221</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>0.508139</td>\n",
       "      <td>1.910864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.720082</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.750309</td>\n",
       "      <td>13.740741</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>-6.222222</td>\n",
       "      <td>-10.222222</td>\n",
       "      <td>16.444445</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>0.463329</td>\n",
       "      <td>1.941465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>2.195113</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.520234</td>\n",
       "      <td>12.259259</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>9.333334</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>-5.777778</td>\n",
       "      <td>-8.777778</td>\n",
       "      <td>14.555555</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>0.480149</td>\n",
       "      <td>1.987902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>1.254621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>12.703704</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>16.222221</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>1.875362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.005540</td>\n",
       "      <td>15.592592</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>11.777778</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.444445</td>\n",
       "      <td>16.555555</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>1.863654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.646930</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.620633</td>\n",
       "      <td>12.111111</td>\n",
       "      <td>10.222222</td>\n",
       "      <td>8.111112</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-5.666666</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>17.666666</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>1.877146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944445</td>\n",
       "      <td>1.083547</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.632993</td>\n",
       "      <td>14.629630</td>\n",
       "      <td>13.222222</td>\n",
       "      <td>11.444445</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>-4.222222</td>\n",
       "      <td>-9.555555</td>\n",
       "      <td>13.777778</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>0.408965</td>\n",
       "      <td>1.860191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611111</td>\n",
       "      <td>0.646930</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>1.722401</td>\n",
       "      <td>15.296296</td>\n",
       "      <td>14.777778</td>\n",
       "      <td>12.888889</td>\n",
       "      <td>18.222221</td>\n",
       "      <td>-1.555556</td>\n",
       "      <td>-7.222222</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>18.222221</td>\n",
       "      <td>0.312227</td>\n",
       "      <td>1.783512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>2.146487</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>1.327766</td>\n",
       "      <td>14.481482</td>\n",
       "      <td>12.555555</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>19.555555</td>\n",
       "      <td>-5.777778</td>\n",
       "      <td>-9.444445</td>\n",
       "      <td>15.222222</td>\n",
       "      <td>19.555555</td>\n",
       "      <td>0.422174</td>\n",
       "      <td>1.950405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>1.985130</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>1.614747</td>\n",
       "      <td>13.703704</td>\n",
       "      <td>11.222222</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>18.777779</td>\n",
       "      <td>-7.444445</td>\n",
       "      <td>-7.777778</td>\n",
       "      <td>15.222222</td>\n",
       "      <td>18.777779</td>\n",
       "      <td>0.439852</td>\n",
       "      <td>2.099904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1   2         3    4         5         6         7         8   \\\n",
       "0  110.0  189.0   9  0.000000  0.0  1.000000  0.666667  1.222222  1.186342   \n",
       "1   86.0  187.0   9  0.000000  0.0  1.111111  0.720082  1.444444  0.750309   \n",
       "2  225.0  244.0   9  0.000000  0.0  3.388889  2.195113  3.000000  1.520234   \n",
       "3   47.0  232.0   9  0.000000  0.0  1.277778  1.254621  1.000000  0.894427   \n",
       "4   97.0  186.0   9  0.000000  0.0  1.166667  0.691215  1.166667  1.005540   \n",
       "5  157.0  221.0   9  0.000000  0.0  1.055556  0.646930  1.222222  0.620633   \n",
       "6   62.0  224.0   9  0.000000  0.0  0.944445  1.083547  2.333333  1.632993   \n",
       "7   27.0  248.0   9  0.111111  0.0  1.611111  0.646930  3.166667  1.722401   \n",
       "8   44.0  233.0   9  0.000000  0.0  2.222222  2.146487  2.111111  1.327766   \n",
       "9   17.0  229.0   9  0.000000  0.0  2.111111  1.985130  2.444445  1.614747   \n",
       "\n",
       "          9          10         11         12        13         14         15  \\\n",
       "0  12.925926  10.888889   9.222222  18.666668 -6.111111 -11.111111  17.222221   \n",
       "1  13.740741  11.666667  10.333334  19.222221 -6.222222 -10.222222  16.444445   \n",
       "2  12.259259  10.333334   9.333334  17.111110 -5.777778  -8.777778  14.555555   \n",
       "3  12.703704  11.000000   9.000000  18.111110 -5.111111 -11.111111  16.222221   \n",
       "4  15.592592  13.888889  11.777778  21.111110 -5.111111 -11.444445  16.555555   \n",
       "5  12.111111  10.222222   8.111112  18.000000 -5.666666 -12.000000  17.666666   \n",
       "6  14.629630  13.222222  11.444445  19.222221 -4.222222  -9.555555  13.777778   \n",
       "7  15.296296  14.777778  12.888889  18.222221 -1.555556  -7.222222   8.777778   \n",
       "8  14.481482  12.555555  11.333333  19.555555 -5.777778  -9.444445  15.222222   \n",
       "9  13.703704  11.222222  11.111111  18.777779 -7.444445  -7.777778  15.222222   \n",
       "\n",
       "          16        17        18  \n",
       "0  18.666668  0.508139  1.910864  \n",
       "1  19.222221  0.463329  1.941465  \n",
       "2  17.111110  0.480149  1.987902  \n",
       "3  18.111110  0.500966  1.875362  \n",
       "4  21.111110  0.442661  1.863654  \n",
       "5  18.000000  0.549180  1.877146  \n",
       "6  19.222221  0.408965  1.860191  \n",
       "7  18.222221  0.312227  1.783512  \n",
       "8  19.555555  0.422174  1.950405  \n",
       "9  18.777779  0.439852  2.099904  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(DATA_PATH + \"segmentation_data.txt\", header=None)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Also load in the numeric class labels from the segmentation class file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(DATA_PATH + \"segmentation_classes.txt\", header=None, sep=\"\\t\").iloc[:, 1]\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REGION-CENTROID-COL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REGION-CENTROID-ROW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REGION-PIXEL-COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHORT-LINE-DENSITY-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHORT-LINE-DENSITY-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "0   REGION-CENTROID-COL\n",
       "1   REGION-CENTROID-ROW\n",
       "2    REGION-PIXEL-COUNT\n",
       "3  SHORT-LINE-DENSITY-5\n",
       "4  SHORT-LINE-DENSITY-2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv(DATA_PATH + \"segmentation_names.txt\", header=None, sep=\"\\t\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using your favorite method (e.g., sklearn's min-max scaler), perform min-max normalization on the data matrix\n",
    "    so that each feature is scaled to [0,1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.30830040e-01, 7.41666667e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.42205474e-02, 6.72233922e-04, 2.73291926e-02,\n",
       "        8.55743510e-04, 9.01110284e-02, 7.94165331e-02, 6.11192912e-02,\n",
       "        1.30943107e-01, 7.31343290e-01, 1.41176540e-02, 8.72865267e-01,\n",
       "        1.23711348e-01, 5.08138840e-01, 8.31849232e-01],\n",
       "       [3.35968379e-01, 7.33333333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.80228046e-02, 7.26095734e-04, 3.22981359e-02,\n",
       "        5.41219947e-04, 9.57913810e-02, 8.50891441e-02, 6.84830672e-02,\n",
       "        1.34840205e-01, 7.29477615e-01, 2.35294199e-02, 8.59582565e-01,\n",
       "        1.27393216e-01, 4.63329080e-01, 8.36986460e-01],\n",
       "       [8.85375494e-01, 9.70833333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.15969577e-01, 2.21344355e-03, 6.70807367e-02,\n",
       "        1.09658970e-03, 8.54634659e-02, 7.53646732e-02, 6.18556741e-02,\n",
       "        1.20031165e-01, 7.36940304e-01, 3.88235327e-02, 8.27324481e-01,\n",
       "        1.13402054e-01, 4.80149030e-01, 8.44782328e-01],\n",
       "       [1.81818182e-01, 9.20833333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.37262383e-02, 1.26509804e-03, 2.23602471e-02,\n",
       "        6.45176713e-04, 8.85618432e-02, 8.02269050e-02, 5.96465386e-02,\n",
       "        1.27045974e-01, 7.48134334e-01, 1.41176540e-02, 8.55787468e-01,\n",
       "        1.20029447e-01, 5.00965950e-01, 8.25889142e-01],\n",
       "       [3.79446640e-01, 7.29166667e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.99239709e-02, 6.96986866e-04, 2.60869646e-02,\n",
       "        7.25325858e-04, 1.08701264e-01, 1.01296598e-01, 7.80559656e-02,\n",
       "        1.48090401e-01, 7.48134334e-01, 1.05882352e-02, 8.61480079e-01,\n",
       "        1.39911626e-01, 4.42660570e-01, 8.23923576e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_norm = scaler.fit_transform(X)\n",
    "X_norm[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Using the Kmeans implementation in scikit-learn, perform clustering on the image data (use K = 7 in your \n",
    "    clustering so that later we can compare the clusters to the 7 pre-assigned image classes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KMeans code taken from lecture notebook\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Can only use Euclidean distance with sklearn KMeans\n",
    "kmeans = KMeans(n_clusters=7,max_iter=1000,verbose=0)\n",
    "kmeans.fit(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 4, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4,\n",
       "       4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 3,\n",
       "       3, 4, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 3, 4, 3, 3, 4, 0,\n",
       "       4, 3, 4, 3, 4, 3, 3, 3, 2, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 3,\n",
       "       4, 4, 4, 3, 3, 3, 4, 2, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 2, 3, 3,\n",
       "       3, 2, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 4, 4, 4, 3, 4, 4, 3, 4, 2, 3, 3, 4, 3, 3, 3, 4, 3, 2, 4, 3, 3,\n",
       "       3, 3, 4, 3, 2, 3, 3, 3, 3, 3, 4, 3, 2, 3, 4, 4, 3, 4, 3, 3, 4, 4,\n",
       "       4, 3, 3, 4, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 2, 4, 3, 4,\n",
       "       3, 3, 3, 4, 2, 4, 3, 2, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 3, 6, 2,\n",
       "       6, 2, 2, 6, 2, 0, 2, 6, 2, 2, 2, 6, 6, 6, 6, 2, 2, 6, 6, 2, 2, 6,\n",
       "       2, 2, 2, 2, 2, 6, 6, 2, 6, 2, 2, 6, 2, 6, 6, 6, 6, 2, 6, 2, 6, 3,\n",
       "       6, 6, 3, 6, 2, 2, 6, 6, 2, 3, 2, 6, 6, 6, 6, 6, 2, 6, 6, 6, 2, 6,\n",
       "       2, 6, 0, 2, 2, 6, 6, 2, 6, 2, 6, 2, 2, 6, 6, 6, 6, 6, 6, 6, 2, 2,\n",
       "       2, 2, 2, 6, 6, 6, 6, 2, 2, 6, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = kmeans.predict(X_norm)\n",
    "clusters[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Print the cluster centroids (use some formatting so that they are visually understandable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(REGION-CENTROID-COL,)</th>\n",
       "      <th>(REGION-CENTROID-ROW,)</th>\n",
       "      <th>(REGION-PIXEL-COUNT,)</th>\n",
       "      <th>(SHORT-LINE-DENSITY-5,)</th>\n",
       "      <th>(SHORT-LINE-DENSITY-2,)</th>\n",
       "      <th>(VEDGE-MEAN,)</th>\n",
       "      <th>(VEDGE-SD,)</th>\n",
       "      <th>(HEDGE-MEAN,)</th>\n",
       "      <th>(HEDGE-SD,)</th>\n",
       "      <th>(INTENSITY-MEAN,)</th>\n",
       "      <th>(RAWRED-MEAN,)</th>\n",
       "      <th>(RAWBLUE-MEAN,)</th>\n",
       "      <th>(RAWGREEN-MEAN,)</th>\n",
       "      <th>(EXRED-MEAN,)</th>\n",
       "      <th>(EXBLUE-MEAN,)</th>\n",
       "      <th>(EXGREEN-MEAN,)</th>\n",
       "      <th>(VALUE-MEAN,)</th>\n",
       "      <th>(SATURATION-MEAN,)</th>\n",
       "      <th>(HUE-MEAN,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (REGION-CENTROID-COL,)  (REGION-CENTROID-ROW,)  (REGION-PIXEL-COUNT,)  \\\n",
       "0                    0.77                    0.43                   0.00   \n",
       "1                    0.54                    0.15                   0.00   \n",
       "2                    0.25                    0.39                   0.00   \n",
       "3                    0.30                    0.53                   0.00   \n",
       "4                    0.75                    0.53                   0.00   \n",
       "5                    0.51                    0.81                   0.00   \n",
       "6                    0.25                    0.46                   0.00   \n",
       "\n",
       "   (SHORT-LINE-DENSITY-5,)  (SHORT-LINE-DENSITY-2,)  (VEDGE-MEAN,)  \\\n",
       "0                     0.01                     0.02           0.04   \n",
       "1                     0.03                     0.00           0.03   \n",
       "2                     0.08                     0.02           0.08   \n",
       "3                     0.05                     0.05           0.10   \n",
       "4                     0.04                     0.04           0.11   \n",
       "5                     0.08                     0.01           0.05   \n",
       "6                     0.03                     0.01           0.04   \n",
       "\n",
       "   (VEDGE-SD,)  (HEDGE-MEAN,)  (HEDGE-SD,)  (INTENSITY-MEAN,)  (RAWRED-MEAN,)  \\\n",
       "0         0.00           0.02         0.00               0.04            0.04   \n",
       "1         0.00           0.03         0.00               0.82            0.78   \n",
       "2         0.00           0.06         0.01               0.15            0.14   \n",
       "3         0.01           0.08         0.01               0.40            0.37   \n",
       "4         0.02           0.11         0.02               0.30            0.28   \n",
       "5         0.00           0.05         0.00               0.11            0.09   \n",
       "6         0.00           0.03         0.00               0.03            0.02   \n",
       "\n",
       "   (RAWBLUE-MEAN,)  (RAWGREEN-MEAN,)  (EXRED-MEAN,)  (EXBLUE-MEAN,)  \\\n",
       "0             0.06              0.03           0.78            0.22   \n",
       "1             0.89              0.79           0.27            0.67   \n",
       "2             0.18              0.12           0.72            0.34   \n",
       "3             0.47              0.35           0.50            0.57   \n",
       "4             0.35              0.26           0.59            0.45   \n",
       "5             0.09              0.14           0.68            0.08   \n",
       "6             0.04              0.02           0.77            0.22   \n",
       "\n",
       "   (EXGREEN-MEAN,)  (VALUE-MEAN,)  (SATURATION-MEAN,)  (HUE-MEAN,)  \n",
       "0             0.49           0.06                0.54         0.24  \n",
       "1             0.29           0.89                0.21         0.13  \n",
       "2             0.35           0.18                0.41         0.20  \n",
       "3             0.21           0.47                0.30         0.16  \n",
       "4             0.31           0.35                0.30         0.16  \n",
       "5             0.82           0.13                0.41         0.89  \n",
       "6             0.51           0.04                0.80         0.18  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format='{:,.2f}'.format\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=features)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    To evaluate your clusters, first perform Silhouette analysis on the clusters (compute Silhouette values for all \n",
    "    instances in the data, and then compute the overall mean Silhouette value; optionally, you can provide a \n",
    "    visaulization of the Silhouettes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57195855 0.56061696 0.46584172 0.49525752 0.57148607 0.56037254\n",
      " 0.54219915 0.41198301 0.51977154 0.46745225 0.48670362 0.49111974\n",
      " 0.58463969 0.56217401 0.37949564 0.53086078 0.54919193 0.42232372\n",
      " 0.41618572 0.40389039]\n"
     ]
    }
   ],
   "source": [
    "# Silhouette analysis code taken from lecture notebooks\n",
    "from sklearn import metrics\n",
    "\n",
    "silhouettes = metrics.silhouette_samples(X_norm, clusters)\n",
    "print(silhouettes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3319445654286108\n"
     ]
    }
   ],
   "source": [
    "print(silhouettes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import pylab as pl\n",
    "\n",
    "def plot_silhouettes(data, clusters, metric='euclidean'):\n",
    "    \n",
    "    from matplotlib import cm\n",
    "    from sklearn.metrics import silhouette_samples\n",
    "\n",
    "    cluster_labels = np.unique(clusters)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = metrics.silhouette_samples(data, clusters, metric='euclidean')\n",
    "    c_ax_lower, c_ax_upper = 0, 0\n",
    "    cticks = []\n",
    "    for i, k in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[clusters == k]\n",
    "        c_silhouette_vals.sort()\n",
    "        c_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        pl.barh(range(c_ax_lower, c_ax_upper), c_silhouette_vals, height=1.0, \n",
    "                      edgecolor='none', color=color)\n",
    "\n",
    "        cticks.append((c_ax_lower + c_ax_upper) / 2)\n",
    "        c_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    pl.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n",
    "\n",
    "    pl.yticks(cticks, cluster_labels)\n",
    "    pl.ylabel('Cluster')\n",
    "    pl.xlabel('Silhouette coefficient')\n",
    "\n",
    "    pl.tight_layout()\n",
    "    #pl.savefig('images/11_04.png', dpi=300)\n",
    "    pl.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(X_norm, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Next, compare your 7 clusters to the 7 pre-assigned classes by computing the Completeness and Homogeneity \n",
    "    values of the generated clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6126955100131936\n"
     ]
    }
   ],
   "source": [
    "# Code for homogeneity and completeness taken from lecture notebooks\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "print(completeness_score(y,clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6110134349673197\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y,clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    c. Perform PCA on the normalized image data matrix. \n",
    "    \n",
    "    You may use the linear algebra package in Numpy or the Decomposition module in scikit-learn (the latter is much more efficient). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08  0.    0.   -0.   -0.   -0.    0.   -0.    0.    0.    0.    0.01  0.01 -0.01  0.    0.\n",
      "   0.01 -0.01  0.  ]\n",
      " [ 0.    0.06  0.    0.    0.    0.   -0.    0.   -0.   -0.03 -0.03 -0.03 -0.03  0.02 -0.02  0.02\n",
      "  -0.03  0.    0.04]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.  ]\n",
      " [-0.    0.    0.    0.02 -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.   -0.    0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.    0.    0.   -0.    0.01  0.    0.    0.    0.   -0.   -0.   -0.   -0.   -0.    0.   -0.\n",
      "  -0.    0.   -0.  ]\n",
      " [-0.    0.    0.   -0.    0.    0.01  0.    0.    0.   -0.   -0.    0.   -0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.    0.   -0.    0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.\n",
      "   0.    0.   -0.  ]\n",
      " [-0.    0.    0.   -0.    0.    0.    0.    0.01  0.    0.    0.    0.    0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.    0.   -0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.03  0.   -0.   -0.   -0.   -0.    0.    0.    0.07  0.07  0.08  0.07 -0.04  0.04 -0.03\n",
      "   0.08 -0.04 -0.02]\n",
      " [ 0.   -0.03  0.   -0.   -0.   -0.   -0.    0.    0.    0.07  0.07  0.07  0.06 -0.04  0.04 -0.03\n",
      "   0.07 -0.04 -0.02]\n",
      " [ 0.01 -0.03  0.   -0.   -0.    0.    0.    0.    0.    0.08  0.07  0.08  0.07 -0.05  0.05 -0.03\n",
      "   0.08 -0.04 -0.03]\n",
      " [ 0.01 -0.03  0.   -0.   -0.   -0.    0.    0.    0.    0.07  0.06  0.07  0.06 -0.04  0.04 -0.02\n",
      "   0.07 -0.04 -0.02]\n",
      " [-0.01  0.02  0.    0.   -0.   -0.   -0.   -0.   -0.   -0.04 -0.04 -0.05 -0.04  0.04 -0.03  0.02\n",
      "  -0.05  0.02  0.01]\n",
      " [ 0.   -0.02  0.   -0.    0.    0.    0.    0.    0.    0.04  0.04  0.05  0.04 -0.03  0.04 -0.03\n",
      "   0.05 -0.02 -0.03]\n",
      " [ 0.    0.02  0.    0.   -0.   -0.    0.   -0.   -0.   -0.03 -0.03 -0.03 -0.02  0.02 -0.03  0.04\n",
      "  -0.03  0.01  0.04]\n",
      " [ 0.01 -0.03  0.   -0.   -0.    0.    0.    0.    0.    0.08  0.07  0.08  0.07 -0.05  0.05 -0.03\n",
      "   0.08 -0.04 -0.03]\n",
      " [-0.01  0.    0.   -0.    0.   -0.    0.   -0.   -0.   -0.04 -0.04 -0.04 -0.04  0.02 -0.02  0.01\n",
      "  -0.04  0.05 -0.  ]\n",
      " [ 0.    0.04  0.    0.   -0.   -0.   -0.   -0.   -0.   -0.02 -0.02 -0.03 -0.02  0.01 -0.03  0.04\n",
      "  -0.03 -0.    0.07]]\n"
     ]
    }
   ],
   "source": [
    "# PCA code taken from lecture notebooks\n",
    "from sklearn import decomposition\n",
    "\n",
    "meanVals = np.mean(X_norm, axis=0)\n",
    "meanRemoved = X_norm - meanVals #remove mean\n",
    "covMat = np.cov(meanRemoved, rowvar=0)\n",
    "\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "print(covMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:  [0.48 0.1  0.08 0.04 0.03 0.02 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "Eigenvectors: [[ 0.03 -0.35  0.93  0.04 -0.01  0.03  0.01  0.03 -0.   -0.02 -0.01  0.01 -0.    0.    0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.19 -0.38 -0.12 -0.66 -0.47  0.14 -0.24  0.22  0.06  0.07  0.06 -0.04 -0.01 -0.01  0.    0.\n",
      "  -0.   -0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.  ]\n",
      " [-0.01 -0.03 -0.04 -0.03  0.06  0.6   0.72  0.32  0.06  0.08  0.01 -0.01 -0.   -0.    0.    0.\n",
      "   0.    0.    0.  ]\n",
      " [-0.    0.02  0.01 -0.1  -0.09 -0.44  0.28  0.32 -0.77  0.05  0.07 -0.    0.01  0.   -0.   -0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.    0.02  0.01 -0.12 -0.03 -0.42  0.3   0.11  0.44 -0.34  0.55  0.28 -0.11 -0.01 -0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [ 0.    0.01  0.01 -0.01 -0.01 -0.18  0.12  0.07  0.18 -0.14  0.05 -0.77  0.55  0.01 -0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.01  0.   -0.   -0.14 -0.03 -0.33  0.19  0.16  0.29 -0.02 -0.77  0.29  0.21 -0.01 -0.   -0.\n",
      "   0.   -0.    0.  ]\n",
      " [ 0.    0.    0.   -0.02 -0.01 -0.16  0.09  0.07  0.13 -0.05 -0.24 -0.49 -0.8   0.01  0.   -0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.38 -0.11 -0.06  0.09 -0.05  0.02 -0.08  0.16  0.01 -0.05  0.    0.   -0.   -0.21  0.74 -0.02\n",
      "   0.11  0.36  0.  ]\n",
      " [ 0.36 -0.11 -0.07  0.09  0.01  0.04 -0.13  0.24  0.   -0.11 -0.    0.01 -0.   -0.21 -0.06  0.5\n",
      "  -0.62  0.1   0.  ]\n",
      " [ 0.41 -0.07 -0.04  0.03 -0.08  0.03 -0.04  0.07 -0.01 -0.06 -0.01 -0.   -0.   -0.22 -0.16 -0.81\n",
      "  -0.16 -0.08  0.  ]\n",
      " [ 0.36 -0.16 -0.08  0.14 -0.06 -0.01 -0.08  0.18  0.04  0.02  0.02  0.   -0.   -0.21 -0.53  0.27\n",
      "   0.69 -0.39  0.  ]\n",
      " [-0.24  0.06  0.    0.01  0.39  0.13 -0.31  0.5  -0.05 -0.42 -0.04  0.03 -0.    0.08 -0.2  -0.11\n",
      "  -0.06  0.37  0.  ]\n",
      " [ 0.26  0.18  0.08 -0.27 -0.18  0.04  0.18 -0.4  -0.08 -0.08 -0.04 -0.02  0.   -0.08 -0.3   0.1\n",
      "  -0.2   0.62  0.  ]\n",
      " [-0.18 -0.34 -0.13  0.43 -0.11 -0.2   0.03  0.14  0.17  0.55  0.1   0.    0.    0.05 -0.13 -0.08\n",
      "  -0.24  0.43  0.  ]\n",
      " [ 0.41 -0.1  -0.06  0.04 -0.1   0.02 -0.03  0.06 -0.   -0.07 -0.01  0.02  0.    0.89 -0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.2   0.31  0.08  0.42 -0.74  0.12 -0.03  0.13 -0.01 -0.3  -0.06  0.03  0.   -0.01 -0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [-0.17 -0.64 -0.24  0.2   0.01  0.02  0.18 -0.35 -0.18 -0.5  -0.12  0.02  0.   -0.04 -0.    0.\n",
      "  -0.   -0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as la\n",
    "eigVals,eigVects = la.eig(np.mat(covMat))\n",
    "print(\"Eigenvalues: \",eigVals)\n",
    "print(\"Eigenvectors:\",eigVects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48 0.1  0.08 0.04 0.03 0.02 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "[60.71 13.2  10.12  4.54  3.55  1.99  1.89  1.62  1.07  0.71  0.39  0.16  0.05  0.    0.    0.\n",
      "  0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "eigValInd = np.argsort(eigVals)  #sort, sort goes smallest to largest\n",
    "eigValInd = eigValInd[::-1]   #reverse\n",
    "sortedEigVals = eigVals[eigValInd]\n",
    "print(sortedEigVals)\n",
    "total = sum(sortedEigVals)\n",
    "varPercentage = sortedEigVals/total*100\n",
    "print(varPercentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Analyze the principal components to determine the number, r, of PCs needed to capture at least 95% of variance in the data.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PCs: 60.714233968533236\n",
      "2 PCs: 73.91121320168925\n",
      "3 PCs: 84.03498614256189\n",
      "4 PCs: 88.57852534332582\n",
      "5 PCs: 92.12588648109565\n",
      "6 PCs: 94.1139219796062\n",
      "7 PCs: 96.00589227704954\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(10):\n",
    "    total += varPercentage[i]\n",
    "    print(\"{} PCs: {}\".format(i+1, total))\n",
    "    if total >= 95: break\n",
    "        \n",
    "topNfeat = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows us that we will need 7 principal compents to capture 95% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Provide a plot of PC variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxcdZnv8c9T1Wt6SXXS3SFLNwESSMKSbokIAg7rveMKOiiOy0THkTtXEbfroKMz4mxXvW7gNiCiqIAKiiAiAoEgoJKdhJBAQsjSZOkOSac7S29Vz/3jnE4qoZdK6KpT3fV9v171qnNOV53zVEGe86vfau6OiIgUjljUAYiISG4p8YuIFBglfhGRAqPELyJSYJT4RUQKTFHUAWSitrbWp0+fHnUYIiKjytKlS3e6e92Rx0dF4p8+fTpLliyJOgwRkVHFzDYNdFxVPSIiBUaJX0SkwCjxi4gUGCV+EZECo8QvIlJgxnTib+3o4l03/pnWzq6oQxERyRtjOvHfsGAdizfu4oYF66MORUQkb2Q18ZtZwszuMrO1ZrbGzM4xswlm9pCZrQufa7Jx7daOLn6xZAvucNeSLSr1i4iEsl3ivx54wN1nAXOBNcBngQXuPhNYEO6PuBsWrKMvGaw1kHRXqV9EJJS1xG9m1cAbgB8CuHuPu7cDlwG3hi+7Fbh8pK/d2tHFnUtb6F9ipjfpKvWLiISyWeI/EWgDfmRmy83sZjOrACa5+zaA8Ll+pC98w4J1pI5YWUylfhGRQDYTfxHwGuD77t4M7OMoqnXM7CozW2JmS9ra2o7qwss2t9ObPDzx9yadZZt2H9V5RETGIsvWmrtmdhzwF3efHu6fT5D4ZwAXuPs2M5sMLHT3U4Y617x58/xYJ2l70/WPM6GihJ/9w+uO6f0iIqOVmS1193lHHs9aid/dtwNbzKw/qV8MPAvcC8wPj80H7slWDADNjQme3tJOKqVF5UVEIPu9ej4G3GZmK4Em4L+ALwOXmtk64NJwP2uaGhJ0dvexYefebF5GRGTUyOp8/O6+AnjFzwyC0n9ONDcmAFi+uZ0Z9VW5uqyISN4a0yN3AU6sraSqrIjlW9qjDkVEJC+M+cQfixlNDQlWbFbiFxGBAkj8ENTzP7ejk/09fVGHIiISuYJI/M2NCZIpZ1XLnqhDERGJXEEk/rnTggbeFarnFxEpjMQ/sbKUxgnjlPhFRCiQxA9BPf9yNfCKiBRO4m9uTLC9o4vtezRDp4gUtoJJ/E0N/fX8mqhNRApbwST+OVOqKYnHVN0jIgWvYBJ/aVGcOVOqNYJXRApewSR+CKp7VrXsoS+ZijoUEZHIFFTib25McKA3yfM7NFOniBSuwkr8DTUALFcDr4gUsIJK/A0TyplQUaIJ20SkoBVU4jcLZ+pUA6+IFLCCSvwQNPCub9tLR1dv1KGIiESi4BJ/c2MCd1i5RTN1ikhhKrjEf8Y0jeAVkcJWcIl/fHkxJ9VVaASviBSsgkv8AM2NNazY0o67Rx2KiEjOFWTib2pI8PK+Hlp2H4g6FBGRnCvYxA+wbLPq+UWk8BRk4p91XBVlxTH15xeRglSUzZOb2UagE0gCfe4+z8wmAL8ApgMbgXe5e06L3kXxGGdM1UAuESlMuSjxX+juTe4+L9z/LLDA3WcCC8L9nGtqTLB6awfdfckoLi8iEpkoqnouA24Nt28FLo8gBpobEvT0pVizrTOKy4uIRCbbid+BB81sqZldFR6b5O7bAMLn+izHMKCmxnAglxp4RaTAZLWOHzjX3beaWT3wkJmtzfSN4Y3iKoDGxsYRD2zy+HImVZeqnl9ECk5WS/zuvjV8bgXuBs4CdpjZZIDwuXWQ997k7vPcfV5dXV1W4mtqSGgpRhEpOFlL/GZWYWZV/dvA/wCeAe4F5ocvmw/ck60YhtPcWMOml/eza19PVCGIiORcNkv8k4AnzOxpYBHwO3d/APgycKmZrQMuDfcj0T+Q62mV+kWkgGStjt/dNwBzBzj+MnBxtq57NE6fOp6YwfLNu7lwViRtzCIiOVeQI3f7VZQWccpx1arnF5GCklHiN7NyMzsl28FEoakhwdNb2kmlNFOniBSGYRO/mb0VWAE8EO43mdm92Q4sV5obEnR09fHiy/uiDkVEJCcyKfFfR9ANsx3A3VcQzLMzJjSHA7m0MIuIFIpMEn+fu4/ZBWpPqqukqrRISzGKSMHIpFfPM2b2HiBuZjOBa4A/ZTes3InFjDMaxmsEr4gUjExK/B8DTgW6gduBPcAnshlUrjU31LBmWycHejRTp4iMfcOW+N19P/D58DEmNTUkSKacZ7bu4bXTJ0QdjohIVmXSq+chM0uk7deY2R+yG1ZuHZqpU9U9IjL2ZVLVU+vuBzNiuFrWmBrmWltZyrSacpargVdECkAmiT9lZgfnRTaz4wnm2R9TmhtrVOIXkYKQSeL/PMFkaz81s58CfwQ+l92wcq+pIcHWPV3s6OiKOhQRkawaNvGHM2q+hmCB9F8CZ7r7mKrjh0MzdWogl4iMdZlO0lYK7CLoyjnHzN6QvZCiceqUaorjpv78IjLmDdud08y+AlwJrAZS4WEnqPIZM8qK48yZXK0RvCIy5mUycvdy4BR37852MFFrakhw59IWkiknHrOowxERyYpMqno2AMXZDiQfNDfWsL8nyfM7OqMORUQkazIp8e8HVpjZAoJpGwBw92uyFlVE+ht4V2xpZ/bk6oijERHJjkwS/73hY8w7fuI4asYVs2JzO397VuPwbxARGYUymavn1lwEkg/MjLkNCY3gFZExLZO5emaa2V1m9qyZbeh/5CK4KDQ31LCudS+dXb1RhyIikhWZNO7+CPg+0AdcCPwE+Gk2g4pSU2MCd1jVMmbXnhGRApdJ4i939wWAufsmd78OuCi7YUWnaVo4glcDuURkjMqkcbfLzGLAOjO7GniJMTY7Z7rx44o5sa5CUzeIyJiVSYn/E8A4giUXzwTeD8zP9AJmFjez5WZ2X7h/gpk9ZWbrzOwXZlZyLIFnU1NDghVb2nEfc5OQiohkNEnbYnff6+4t7v5Bd3+Hu//lKK7xcWBN2v5XgG+6+0xgN/Chows5+5obEuzc281L7QeiDkVEZMQNmvjN7Fvh82/N7N4jH5mc3MymAW8Gbg73jaB94K7wJbcSTAmRV5obawDN1CkiY9NQdfz9PXe+9irO/y3gn4CqcH8i0O7ufeF+CzB1oDea2VXAVQCNjbkdTHXKcVWUFsVYsaWdt86dktNri4hk26CJ392Xmlkc+LC7v+9oT2xmbwFaw/Nc0H94oEsNcv2bgJsA5s2bl9PK9uJ4jNOnjtcUzSIyJg1Zx+/uSaDuGBtgzwXeZmYbgZ8TVPF8C0iYWf8NZxqw9RjOnXXNjQlWvbSHnr7U8C8WERlFMunVsxF40sz+xcw+1f8Y7k3u/jl3n+bu04F3A4+4+3uBR4ErwpfNB+45ttCzq6mhhp6+FGu3d0QdiojIiMok8W8F7gtfW5X2OFbXAp8ys/UEdf4/fBXnypqmxkMzdYqIjCWZTNL2pVd7EXdfCCwMtzcAZ73ac2bblPFl1FWVsnxzO393TtTRiIiMnEyWXqwj6JlzKlDWf9zdx+y0DRDM1NkcDuQSERlLMqnquQ1YC5wAfImgzn9xFmPKG02NCV7cuY/d+3qiDkVEZMRkkvgnuvsPgV53f8zd/x44O8tx5YWDK3K1qNQvImNHJom/f2L6bWb2ZjNrJuiGOeadMS1BzGCFRvCKyBiSyeyc/2Fm44FPA98GqoFPZjWqPFFZWsTJk6pUzy8iY8qgid/M5rn7Ene/Lzy0h2AhloLS1JDg989sx90JphoSERndhqrq+UE4dfK/mdmcnEWUZ5obE+w50MuLO/dFHYqIyIgYNPG7ezPwFiAJ3GVmK8zsWjM7PmfR5YGmhmCmTlX3iMhYMdxcPc+5+5fcfQ7B9AoJ4BEzezIn0eWBGfWVVJTElfhFZMzIpFcP4dKL9cAkoAJoy2ZQ+SQeM86YltDc/CIyZgyZ+M3sfDP7HsG8+Z8BngBOcfe8Wzwlm5obE6zZ1kFXbzLqUEREXrWhevVsATYTTKn8JXffkbOo8kxTQ4K+lLN66x7OPH5C1OGIiLwqQ/XjP8/dN+UskjzWP1Pn8s3tSvwiMuoN1atHST9UX1XG1EQ5y9XAKyJjQEaNuxKU+jV1g4iMBYMmfjP7Svj8ztyFk7+aGxK81H6A1s6uqEMREXlVhirxv8nMioHP5SqYfNbcvyKXSv0iMsoNlfgfAHYCZ5hZh5l1pj/nKL68ceqU8RTFTAO5RGTUG6px9zPuPh74nbtXu3tV+nMOY8wLZcVxZk+uVuIXkVFv2MZdd7/MzCaZ2VvCR10uAstHzY0Jnt7STjLlUYciInLMhk38YePuIuCdwLuARWZ2RbYDy0dNDQn29SRZ37o36lBERI5ZJguxfAF4rbu3wsHF1x8G7spmYPno4FKMW3ZzynFVEUcjInJsMunHH+tP+qGXM3zfmHNCbQXjy4s1YZuIjGqZlPgfMLM/AHeE+1cC92cvpPxlZjQ1JNTAKyKjWiaNu58BbgTOAOYCN7n7tcO9z8zKzGyRmT1tZqvN7Evh8RPM7Klwda9fmFnJq/0QudTUkOD5HZ3s7e6LOhQRkWOSUZWNu//a3T/l7p9097szPHc3cJG7zwWagL82s7OBrwDfdPeZwG7gQ8cSeFSaGhOkHFa2qNQvIqNT1urqPdDf/aU4fDhwEYcahm8FRtXc/k3T+ht4lfhFZHTKaiOtmcXNbAXQCjwEvAC0u3t/PUkLMHWQ915lZkvMbElbW/4s+FVTUcIJtRWaukFERq1Ml14sN7NTjvbk7p509yZgGnAWMHuglw3y3pvcfZ67z6ury68xY00NCZZvacddA7lEZPTJZADXW4EVBHP3YGZNZnbv0VzE3duBhcDZQMLM+nsTTQO2Hs258kFzY4K2zm627tFMnSIy+mRS4r+OoLTeDuDuK4Dpw73JzOrMLBFulwOXAGuAR4H+kb/zgXuONuioHRzIpeoeERmFMkn8fe6+5xjOPRl41MxWAouBh9z9PuBa4FNmth6YCPzwGM4dqVnHVVNSFGPFlt1RhyIictQyGcD1jJm9B4ib2UzgGuBPw73J3VcCzQMc30DwC2LUKimKcdqUao3gFZFRKZMS/8eAUwn65d8BdACfyGZQo0FzYw2rXtpDbzIVdSgiIkclk5G7+9398+7+2rCXzefdveBbNZsaEnT3pXhue2fUoYiIHJVhq3rM7Le8ssvlHmAJcGOh3gT6G3iXb97NaVPHRxyNiEjmMqnq2QDsBX4QPjqAHcDJ4X5BmlZTTm1lKcs1gldERplMGneb3f0Nafu/NbM/uvsbzGx1tgLLd5qpU0RGq0xK/HVm1ti/E27Xhrs9WYlqlGhuTLChbR979vdGHYqISMYyKfF/GnjCzF4ADDgB+IiZVRBMslawmvsHcrW081cn59e0EiIigxk28bv7/WH//VkEiX9tWoPut7IZXL47fdp4zIIRvEr8IjJaZFLiB5gJnAKUAWeYGe7+k+yFNTpUlRUzs75SI3hFZFTJpDvnF4ELgDkESy6+EXgCKPjED9DcUMODz27H3TGzqMMRERlWJo27VwAXA9vd/YMEyy+WZjWqUaSpMcHu/b1senl/1KGIiGQkk8R/wN1TQJ+ZVRMsqnJidsMaPQ7O1KlunSIySmSS+JeE0yv/AFgKLAMWZTWqUeTkSVWMK4mzfLPq+UVkdMikV89Hws3/NrMHgOpw5k0B4jHjjGnjVeIXkVEjkxW4FvRvu/tGd1+ZfkygqaGGZ7d10NWbjDoUEZFhDZr4zazMzCYAtWZWY2YTwsd0YEquAhwNmhoS9Cad1Vs7og5FRGRYQ1X1/C+CefenENTt9/dV7AC+m+W4RpXmxkMNvGceXxNxNCIiQxs08bv79cD1ZvYxd/92DmMadSZVlzFlfJnq+UVkVMikcffbZvZ6ggXWi9KOawBXmqbGhEbwisiokMnI3Z8CJwErgP7WS0cjdw/T3FDD/au2s3NvN7WVGt8mIvkrk7l65gFz3P3IVbgkTVN/Pf/mdi6ZMyniaEREBpfJAK5ngOOyHchod9qU8cRjpnp+Ecl7mZT4a4FnzWwR0N1/0N3flrWoRqHykjizJ1exXPX8IpLnMkn812U7iLGiqSHBPcu3kko5sZhm6hSR/DRsVY+7PwZsBIrD7cUE8/UMycwazOxRM1tjZqvN7OPh8Qlm9pCZrQufx0zH96aGGjq7+3ihbW/UoYiIDCqTKRs+DNwF3Bgemgr8JoNz9wGfdvfZwNnAR81sDvBZYIG7zwQWhPtjQv9Mncs3q55fRPJXJo27HwXOJRixi7uvA+qHe5O7b3P3ZeF2J7CG4KZxGYfW6r0VuPzow85PJ9ZWUF1WxHI18IpIHssk8Xe7e0//jpkVEfTjz1g4v08z8BQwyd23QXBzYJCbiJldZWZLzGxJW1vb0VwuMrGYMbchoZ49IpLXMkn8j5nZPwPlZnYpcCfw20wvYGaVwK+AT7h7xrOYuftN7j7P3efV1Y2ehcybGxI8t72Dfd19UYciIjKgTBL/Z4E2YBXBxG33A1/I5ORmVkyQ9G9z91+Hh3eY2eTw75MJVvQaM5oba0g5rHppT9ShiIgMKJPEXw7c4u7vdPcrgFvCY0OyYOXxHwJr3P0baX+6F5gfbs8H7jm6kPPbXC3FKCJ5LpPEv4DDE3058HAG7zsXeD9wkZmtCB9vAr4MXGpm64BLw/0xY0JFCcdPHMcK9ewRkTyVyQCuMnc/2DHd3fea2bjh3uTuT3BoDv8jXZxhfKNSc0OCP294OeowREQGlEmJf5+ZvaZ/x8zOBA5kL6TRr6khwY6Obrbt0dckIvknkxL/x4E7zWxruD8ZuDJ7IY1+TY3BYOQVm9uZfPqwzSEiIjk1ZOI3sxhQAswCTiGoulnr7r05iG3Umj25ipJ4jOVb2nnj6ZOjDkdE5DBDJn53T5nZ1939HILpmSUDpUVxTp1arQZeEclLmdTxP2hmfxN2z5QMNTUkWPlSO33JVNShiIgcJpPE/ymC0bo9ZtZhZp1mlvEI3ELV1JCgqzfF2u2dUYciInKYTKZlrnL3mLsXu3t1uF+di+BGs9f0N/BqIJeI5JlMpmU2M3ufmf1LuN9gZmdlP7TRbVpNORMrSpT4RSTvZFLV8z3gHOA94f5e4LtZi2iMMDOaNFOniOShTBL/69z9o0AXgLvvJujiKcNobkywvnUvew6o96uI5I9MEn+vmcUJ5+A3szpAXVUy0NQQ1POvbFGpX0TyRyaJ/wbgbqDezP4TeAL4r6xGNUac0TAeM9SfX0TyyrBTNrj7bWa2lGBiNQMud/c1WY9sDKguK2ZGXaWWYhSRvDJo4jezMuAfgRkEi7Dc6O5aVuooNTUkWLC2FXdHY+BEJB8MVdVzKzCPIOm/EfhaTiIaY5oaE+za18Pl332S1s6uqMMRERky8c9x9/e5+43AFcAbchTTmNIUrsi1smUPNyxYH3E0IiJDJ/6DfRBVxXPsasqLgaBL1B2LNvPo2lZSKY82KBEpaEM17s5Nm5PHgPJw3wDXtA2Z+d7CF4jHjGTKSaacD/54MbWVpVw0q46LZ0/ivBm1VJRmsiyCiMjIGDTjuHs8l4GMRa0dXdy5tIVkWgm/OG40NYzn989s55dLWigpinHOiRO5eHY9F8+exNSEFm4RkexSUTOLbliwjpS/slrnuPHlLPuXS1n84i4WrG1lwZod/Os9q/nXe1Yz67gqLpk9iYtm19M0LUEspp5AIjKylPizaNnmdnqThyf+3qSzbNNuiuMxXj+jltfPqOULb57NC237eGTtDh5e08r3H3uB7zy6ntrKEi48pZ6LZ9dz/sw6VQmJyIgwH6BEmm/mzZvnS5YsiTqMnGnf38Njz7fx8JpWFj7XSmdXHyXxGGefNJGLZwU3gmk146IOU0TynJktdfd5rziuxJ/fepMplmzczYI1O3hkbSsbdu4DYNZxVVw0K2gXaGpIEFeVkIgcQYl/jNjQtpcFa1pZsHYHizfuJplyJlaUcMEp9Vwyu57zT66jUlVCIkIEid/MbgHeArS6+2nhsQnAL4DpwEbgXeE0z0NS4h/Ynv29PLaujQVrdrDwuTb2HOilOG6cfWJ/ldAkGiYcqhJq7eji6juW8533NFNfVRZh5CKSC1Ek/jcQLNryk7TE/1Vgl7t/2cw+C9S4+7XDnUuJf3h9yRRLN+1mwdpWHl6zgw1tQZXQyZMquXj2JC6eVc/dy1/i9kWbee/rjuc/Lj8t4ohFJNsiqeoxs+nAfWmJ/zngAnffZmaTgYXufspw51HiP3ov7tx3sF1g0Yu76EsbS1BaFOPxay9UqV9kjBss8WcyH/9ImuTu2wDC5/rBXmhmV5nZEjNb0tbWlrMAx4oTaiv4h/NP5PYPn83Sf7mU82ZMpL/5t7svxdW3LaM3qfV0RApRrhN/xtz9Jnef5+7z6urqog5nVOvuTbJ4427Sf9st2ribi76+kPtXbWM0NPCLyMjJdeLfEVbxED635vj6BWmgEcTxmNFxoJeP3LaMt3/vTzy14eWIohORXMt14r8XmB9uzwfuyfH1C9JAI4iTKWdKYhxf/Zsz2L6niytv+gsf+vFint/RGVGUIpIr2ezVcwdwAVAL7AC+CPwG+CXQCGwG3unuu4Y7lxp3s+tAT5JbnnyR/174Avt6+njnmQ188tKTOW68Gn9FRjMN4JJh7drXw3ceWc9P/7KReMz4+3NP4B8vOInqsuKoQxORY6DELxnbsms/X3vwOe5ZsZWaccVcfdFM3nd2I6VFmqlbZDTJl+6cMgo0TBjH9e9u5r6PncecKdX8+33Pcsk3HuOeFS9p9TCRMUCJXwZ12tTx/OxDr+PWvz+LytJiPv7zFbztu0/w5PqdUYcmIq+CEr8Mycz4q5Pr+N3HzuMb75rL7n29vPfmp/i7Wxbx7NaO4U8gInlHiV8yEosZ73jNNBZ8+q/4/Jtm8/SWdt787cf51C9W0LJ7f9ThichRUOOuHJM9+3v53mPr+dGTGwGYf87xfPTCGSTGlUQbmIgcpF49khUvtR/gGw8+z6+Xt1BVWsRHL5zB/NdPp6xYPYBEoqZePZIVUxPlfP1dc7n/mvN5zfE1/N/fr+Wiry3kV0tbSKoHkEheUuKXETF7cjU//uBZ3P7h11FbVcqn73yaN9/wOAufa9UkcCJ5RolfRtTrT6rlNx85l2//bTP7e5J84EeLee/NT7GqZQ8QrAL2rhv/TGtnV8SRihQu1fFL1vT0pbjtqU18+5H17NrXw1vnTiFmcO/TW7UKmEgODFbHr1W5JWtKimJ88NwTuOLMadz42AZ+8PgLdPcFBY1fLN7MWdNrOPm4KuqryqgZV4yZDXNGERkJSvySdVVlxfyf/3kKW/cc4DfLXyLl0Jt0rvn5ioOvKY4bdZWl1FWXUVdZSn11KfVVpdRXlQXP1aXUVZVSW1lKcVw1lCKvhhK/5ERrRxe/W7mN9I4+JfEY171tDl29KVo7u2nt7KKts5uW3ftZtnk3u/b1vOI8ZjBhXAl1VaXUV4c3hargplBfVXbYDaO8ZPAupa0dXVx9x3K+855mrT0sBUeJX3JioFXAHOfZbZ2D1vX39KXYubc7uCl0dNG2t5vWjmC/rbOL1s5unt/eyc693YctJt+vqrSIuv6bQtpNor66lPue3sbiF3fxrYfW8V/vOD0rn1kkXynxS04MtApYb9JZtmn3oO8pKYoxJVHOlET5kOdOpZzd+3vCXw2H3yTawl8SK1vaae3o5kBv8rD33r5oM39c18bM+kpOrKvkxLoKTqyt5KS6CuqqStXuIGOSEr/kxP0fPz9r547FjImVpUysLGX25MFf5+7s60nyz79eyf2rttOXcmIGcTO27enizxtepqs3dfD1laVF4Y2gghNqw5tCeGMYqhpJJN8p8UvBMDP2d/fxh9U7DlYNpRx2dHTxx2svpLailG0dXWxo28uGtn3B8859LN64m9+s2HrYuaaML0v7hVBxcHvK+HJiMf1KkPymxC8FZaC2hqQ7NyxYz39cfhpTE+VMTZRz/sy6w15zoCfJizv3sWFncFN4cWdwY7h72Ut0dvcdfF1pUYwTag/9Mgh+JQTPAy1hmS+NzPkSh+SGEr8UlGNpawAoL4kzZ0o1c6ZUH3bc3Wnb2x3+Qjj0K+HZrR38YfWOw+Yrqq0sTfuFENwY7n36JRZv3MU3H3qef7vsNGJmxIycty3csGAdizfuOngDjIpuQLmhkbsiWdLTl2LzrvCGEP5C6N8eqKtqOjOImRE3wwziMSN2xHb/TSJmRjw2wOv6XxM79Lr+7f6/mUEy5SzbvJuUQ8zgoln1VJcVU1IUCx7x2KHt9P34AMeKYpQWxSiJxykussOPx+MHt+ODVId94e5V3LZos0Z2jxCN3BXJsZKiGDPqq5hRX/WKv7Xv7+HaX63k4TU7SKYgbsFSlxfNmkTKPe0R9FpKuZNMQcoddyd5xN8Oe52nvS4V/C19++C5U0E116aX99Ff/ks5PLVhF9XlxfQmU/QkU/T0BY+Busweq3gsuCkUx42SojilRTFiMWjZdQAHbn9qE1t372diZSmVZUVUlRZRUVpEZVkRlaVpj7IiqkqLqSiNU1lWRGnRyDS6j/VfHkr8IhHo6Uux8Lk2kmEnoqTDc9s7+cH8eTlNNK0dXZz/1UdJT+m9yRR3f/T1r4gjlXJ6kim6wxtBTzJFb9+hm0P68Z6D20l6+5zu9GPh8Z7DXu8s2bTr0LUclm7azbjSIvZ29bG3p49MKidK4rGDN4HK0uLwhhGnsqyYytIiqsqKqCgpGvBmUlUW7pcWcX0eVH1l8+ajxC8SgeEamfMxjljMKIvFs7LIzkA3oO6+FA99+lzqq8pIpZwDvUn2dvfR2dXH3u4+9h2xfehvvezrTh7cbtvbzcaX9x/cT++yO5yf/WUT96/cxrjS4HOXFccoKwq2S4tiwXNx8Bwcj1EaPh98fXGc0qLwdYf97dA5+s+b3iMsm+0ukSR+M/tr4HogDtzs7l+OIg6RqBxrI/NYjWO4G1AsZhJrkREAAAnxSURBVFSEJfRJ1YOcJEN9yVRwY+juHfAG8svFW1i+pf1gm8eEymJOn5qgqzdJd1+Krt4k+3v62LUvRVdfku7eFN19Sbp6g7+9miqxkniM0uIYxbEYu/YH7UB3LtnCNRfPGNFSf84Tv5nFge8ClwItwGIzu9fdn811LCJRyeaAtqORL3Hk8gZUFI8xflyM8eMG7l77r/esPjinVMqDdofbP3x2xom3L5miqy9Fd2+SrvBGETyCY/03j660m8XBY+H+E+vbaD/Qc7BNZqRL/VGU+M8C1rv7BgAz+zlwGaDEL1Kg8uUGNBJVcEXxGJXxGJWlx5ZeWzu6uGPR5oM3n96kc9cIl/qjmN92KrAlbb8lPHYYM7vKzJaY2ZK2tracBScihSsfqr6GuvmMlChK/AN14H1FpZi73wTcBEE//mwHJSKSD788cnHziSLxtwANafvTgK2DvFZEpKDk4uYTRVXPYmCmmZ1gZiXAu4F7I4hDRKQg5bzE7+59ZnY18AeC7py3uPvqXMchIlKoIunH7+73A/dHcW0RkUKnVatFRAqMEr+ISIEZFdMym1kbsCnqOF6lWmBn1EHkCX0Xh9P3cTh9H4e82u/ieHevO/LgqEj8Y4GZLRloXuxCpO/icPo+Dqfv45BsfReq6hERKTBK/CIiBUaJP3duijqAPKLv4nD6Pg6n7+OQrHwXquMXESkwKvGLiBQYJX4RkQKjxJ9FZtZgZo+a2RozW21mH486pnxgZnEzW25m90UdS9TMLGFmd5nZ2vD/k3OijikqZvbJ8N/JM2Z2h5nlbtX5PGBmt5hZq5k9k3Zsgpk9ZGbrwueakbiWEn929QGfdvfZwNnAR81sTsQx5YOPA2uiDiJPXA884O6zgLkU6PdiZlOBa4B57n4awQSO7442qpz7MfDXRxz7LLDA3WcCC8L9V02JP4vcfZu7Lwu3Own+Ub9itbFCYmbTgDcDN0cdS9TMrBp4A/BDAHfvcff2aKOKVBFQbmZFwDgKbJ0Od/8jsOuIw5cBt4bbtwKXj8S1lPhzxMymA83AU9FGErlvAf8EpKIOJA+cCLQBPwqrvm42s4qog4qCu78EfA3YDGwD9rj7g9FGlRcmufs2CAqSQP1InFSJPwfMrBL4FfAJd++IOp6omNlbgFZ3Xxp1LHmiCHgN8H13bwb2MUI/5UebsO76MuAEYApQYWbvizaqsUuJP8vMrJgg6d/m7r+OOp6InQu8zcw2Aj8HLjKzn0UbUqRagBZ37/8VeBfBjaAQXQK86O5t7t4L/Bp4fcQx5YMdZjYZIHxuHYmTKvFnkZkZQf3tGnf/RtTxRM3dP+fu09x9OkHD3SPuXrClOnffDmwxs1PCQxcDz0YYUpQ2A2eb2bjw383FFGhD9xHuBeaH2/OBe0bipJGswFVAzgXeD6wysxXhsX8OVyATAfgYcFu4/vQG4IMRxxMJd3/KzO4ClhH0hltOgU3dYGZ3ABcAtWbWAnwR+DLwSzP7EMHN8Z0jci1N2SAiUlhU1SMiUmCU+EVECowSv4hIgVHiFxEpMEr8IiIFRolfhmRmSTNbEc6YeKeZjRvkdfebWeIYzj8l7MZ3rPFtNLPaAY5XmtmNZvZCOOPjH83sdcd6nXxgZk1m9qZB/naBmbmZvTXt2H1mdsEIXXvA71lGJyV+Gc4Bd28KZ0zsAf4x/Y8WiLn7m45lgjF33+ruV4xUsGluJpjwaqa7nwp8ABjtiasJGDDxh1qAz+coloyFk65JHlHil6PxODDDzKaHc8d/j2DATUN/iTDtbz8IS9oPmlk5gJnNMLOHzexpM1tmZieFr38m/PsHzOweM3vAzJ4zsy/2X9jMfmNmS8NzXjVUkGZ2EvA64AvungJw9w3u/rvw758Kf8E8Y2afCI9ND+fEvzk8fpuZXWJmT4ZzoZ8Vvu46M/upmT0SHv9weNzM7P+F711lZleGxy8ws4V2aM7928KRqZjZmWb2WPi5/pA2NH+hmX3FzBaZ2fNmdn44wOvfgCvDX2BXDvDRnwb2mNmlA3wnB0vsZjbPzBamfZ5bw/9OG83sHWb21fAzPGDBlCP9PhPGtMjMZoTvrzOzX5nZ4vBxbtp5bzKzB4GfDPXfSyLg7nroMegD2Bs+FxEMF//fwHSC2TXPTnvdRoIS9XSCkZdN4fFfAu8Lt58C3h5ulxFMvTsdeCY89gGCmRknAuXAMwTzswNMCJ/7j09Mv+4RMb8NuHuQz3MmsAqoACqB1QSzpvbHfTpBgWgpcAtgBJOH/SZ8/3UECbY8/LxbCCYV+xvgIYJ55CcRjLKcTDAScw8wLTzvn4HzgGLgT0BdeN4rgVvC7YXA18PtNwEPp30/3xnkc10A3AecDzwWHrsPuODI7wmYByxM+zxPhPHMBfYDbwz/djdwedr7Px9u/x1wX7h9O3BeuN1IMD1J/3mXAuVR/z+sxysf+gkmwym3Q9NNPE4w99AUYJO7/2WQ97zo7v3vWQpMN7MqYKq73w3g7l0AYeE33UPu/nL4t18TJMklwDVm9vbwNQ3ATODlY/g85xHcFPalXeN8gjlRXnT3VeHx1QQLYLiZrSK4MfS7x90PAAfM7FHgrPC8d7h7kmBirceA1wIdwCJ3bwnPuyI8VztwGvBQ+B3ECW56/fon9Ft6xLWH5O6Pmxlmdn6m7wF+7+694eeMAw+Ex4/83HekPX8z3L4EmJP237E6/G8NcG/4PUmeUeKX4Rxw96b0A+E/8n1DvKc7bTtJUDp+RYYfxJFziHjYQHkJcI677w+rKYZalm81MDdsezhy3v+h4kiPO5W2n+LwfyuviPEozpsMz2XAancfbKnF7iNefzT+k6Cuvy/tWB+HqnaP/O66Adw9ZWa9HhbZGfpz92/HCP67HJbgM/h/RCKkOn7JCQ/WIWgxs8sBzKzUBu4hdKkF64yWE6w29CQwHtgdJv1ZBMtYDnWtFwh+JXwprT59ppldBvwRuNyCWSArgLcT/JI5GpeZWZmZTSSoYlkcnvdKC9YTriNYWWvREOd4DqizcI1dMys2s1OHuW4nUDXMa/BgAZMagqqbfhsJqrkgqJY6FlemPf853H4QuLr/BWbWdOSbJP8o8UsuvZ+gymYlQf32cQO85gngp8AK4FfuvoSg6qEofN+/A4NVMaX7h/D868MqjB8AWz1YCvPHBEn5KeBmd19+lJ9jEfC7MI5/d/etBPXhKwnq/x8B/smDaZcH5O49wBXAV8zs6fDzDjf//KME1SqDNe6m+0+CdoV+XwKuN7PHCX5FHItSM3uKYM3kT4bHrgHmmdlKM3uWI3p9SX7S7JySN8zsAwSNuVcP99qomNl1BA3eX4s6FpFjpRK/iEiBUYlfRKTAqMQvIlJglPhFRAqMEr+ISIFR4hcRKTBK/CIiBeb/A00S9jcdGu/bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1, 11), varPercentage[:10], marker='^')\n",
    "plt.xlabel('Principal Component Number')\n",
    "plt.ylabel('Percentage of Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Then use these r components as features to transform the data into a reduced dimension space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69 -0.53 -0.25 ... -0.08 -0.05 -0.05]\n",
      " [-0.67 -0.51 -0.34 ... -0.04 -0.06 -0.04]\n",
      " [-0.71 -0.77  0.16 ... -0.17 -0.04 -0.06]\n",
      " ...\n",
      " [-0.51  0.13  0.08 ... -0.03  0.03 -0.11]\n",
      " [-0.48  0.09  0.16 ...  0.    0.   -0.09]\n",
      " [-0.44  0.11  0.05 ...  0.02  0.21  0.15]]\n"
     ]
    }
   ],
   "source": [
    "topEigValInd = eigValInd[:topNfeat]  #cut off unwanted dimensions\n",
    "reducedEigVects = eigVects[:,topEigValInd]   #reorganize eig vects largest to smallest\n",
    "reducedDT = np.dot(meanRemoved, reducedEigVects)    #transform data into new dimensions\n",
    "print(reducedDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    d. Perform Kmeans again, but this time on the lower dimensional transformed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=7,max_iter=1000,verbose=0)\n",
    "kmeans.fit(reducedDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 2, 3, 3, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3,\n",
       "       2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 3, 3, 2, 3, 2, 2, 3, 6, 3, 2, 3, 2, 3, 2,\n",
       "       2, 2, 5, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 3, 2, 3, 3, 3, 2, 2, 2, 3, 5, 3, 2, 2, 2, 2, 2, 3,\n",
       "       3, 3, 3, 3, 5, 2, 2, 2, 5, 2, 3, 2, 3, 3, 2, 2, 2, 3, 2, 5, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       3, 3, 2, 3, 3, 2, 3, 5, 2, 2, 3, 2, 2, 2, 3, 2, 5, 3, 2, 2, 2, 2, 3, 2, 5, 2, 2, 2, 2, 2, 3,\n",
       "       2, 5, 2, 3, 3, 2, 3, 2, 2, 3, 3, 3, 2, 2, 3, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 5, 3,\n",
       "       2, 3, 2, 2, 2, 3, 5, 3, 2, 5, 3, 3, 3, 3, 3, 2, 2, 2, 3, 2, 3, 2, 0, 5, 0, 5, 5, 0, 5, 6, 5,\n",
       "       0, 5, 5, 5, 0, 0, 0, 0, 5, 5, 0, 0, 5, 5, 0, 5, 5, 5, 5, 5, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 0,\n",
       "       0, 5, 0, 5, 0, 2, 0, 0, 2, 0, 5, 5, 0, 0, 5, 2, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 5, 0, 6,\n",
       "       5, 5, 0, 0, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 1, 1,\n",
       "       1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = kmeans.predict(reducedDT)\n",
    "clusters[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.41</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6\n",
       "0 -0.60  0.36 -0.11  0.13 -0.13  0.02 -0.04\n",
       "1  1.41 -0.09 -0.04  0.17 -0.03  0.01 -0.02\n",
       "2  0.44  0.10 -0.16 -0.23 -0.05  0.01  0.02\n",
       "3  0.18 -0.04  0.27 -0.18  0.03 -0.02  0.00\n",
       "4 -0.62 -0.64 -0.20  0.09 -0.07 -0.01  0.04\n",
       "5 -0.21  0.25 -0.15 -0.06  0.13  0.01  0.03\n",
       "6 -0.51  0.06  0.34  0.07  0.08 -0.01 -0.03"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format='{:,.2f}'.format\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Then compare Silhouette values as well as completeness and Homogeneity values of the new clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35982029813508676\n"
     ]
    }
   ],
   "source": [
    "silhouettes = metrics.silhouette_samples(reducedDT, clusters)\n",
    "print(silhouettes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAarElEQVR4nO3dfbQkdX3n8feXAXlGkBmUCOMIC7isRwdzVwPGOAhBJIBuwIAG1lE3oxg1bDAJIB436hI1McBugDASgWhUWFh2WRYRRWbxAQwzMoyKgoq4jLgKisZnHPzuH1WXaZp7b/ed29VV1fV+ndOn+qG6f5/puXc+U9XVv4rMRJKkptmq7gCSJM3EgpIkNZIFJUlqJAtKktRIFpQkqZG2rjtAr8WLF+eyZcvqjiFNvrvuKpYHHFBvDglYt27dg5m5pP/+RhXUsmXLWLt2bd0xpMm3YkWxXLOmzhQSABHxrZnudxefJKmRLChJUiNZUJKkRmrUZ1CSxuSUU+pOIA1kQUlddMIJdSeQBnIXn9RF991XXKQGcwtK6qKTTy6WHmauBnMLSpLUSBaUJKmR3MXXVAdF3Qk0yb5WLpv+c3a7J1TtMgtK0vhYOJoHC0rqoj3GOJalpC1kQUld9MSKXtcy0ghZUFIX/aJcbjfk+haPamBBSV00/R3d/cqlBaQGsqCkLugvIM8HpRawoKRJ5BaRJoAFJbWFpaOOsaCkprKQ1HEWlFSnukrorLPqGVeaBwtKGpcmbREdfnjdCaSBLCipKk0qpH7r1xfL5cvrzSHNodKCiohdgYuBZwIJvCYzb6lyTGnsmlxEszn11GLpYeZqsKq3oM4Drs/M4yPiCcAOFY8njU8bi0lqkcoKKiJ2AX4HWAmQmQ8DD1c1njRSlo9UuypPWLgP8ABwSUTcHhEXR8SO/StFxKqIWBsRax944IEK40hDspykRqiyoLYGngNcmJkHAT8FTu9fKTNXZ+ZUZk4tWbKkwjhSn9tz5oukRqjyM6iNwMbM/Hx5+0pmKChpbCyfzc4+u+4E0kCVFVRm/r+IuC8iDsjMu4DDgDurGk+alcX0eIccUncCaaCqj+J7E/BP5RF89wCvrng8qWApze1znyuWFpUarNKCysz1wFSVY0iPspSGd+aZxdLvQanBnElC7WUhSRPNglK7WEpSZ1hQah5LSBIWlOpmGUmahQWl0bN0mu/cc+tOIA1kQWkwC2fyeJoNtYAF1QUWjPp98pPF0hMXqsEsqCY5KDZft1RUpXe9q1haUGowC2qUegtGkrQg3Sgoi0OSWqcbBdXG3WU3WKqq0EPlsu6fsyNa+LupselGQUlqDktJQ7KgpC568xjGsIi0QBaU1EV7V/S6lpJGyIKSuujWcvlbW/h8i0hjYEFJXXRVuRy2oCwk1cCCkjQzS0k1s6AkbWYpqUEsKKmrdnshHLGm7hTSrLaqO4CkMToii8tuL6w7iTSQW1DSpJtpt90HPzj+HNI8WVDSJBr0WdLeVX0RShodC0qaFPM5wOHyy4vlCSdUk0UaAQtKaquFHHF34YXF0oJSg1VaUBFxL/Bj4BFgU2ZOVTmeNNE8BFwdM44tqEMz88ExjCNNBotIAtzFJ9XPQpJmVHVBJXBDRCRwUWau7l8hIlYBqwCWLl1acRypRhaRNC9VF9TzM/P+iNgD+EREfDUzb+5doSyt1QBTU1P+BmtyNLmQrryy7gTSQJUWVGbeXy6/FxFXA88Fbp77WVLLNLmIZrN4cd0JpIEqK6iI2BHYKjN/XF4/AnhHVeNJlWtjEc3m0kuL5cqVdaaQ5lTlFtSTgasjYnqcD2fm9RWOJ43OJJXRTCwotUBlBZWZ9wDPrur1pZGY9CKSWszDzDW5LB+p1SwoTQ4LSZooFpTaxyKSOsGCUvNYQNW77rq6E0gDWVCqhyVUrx12qDuBNJAFpfGwkJrlgguK5RveUG8OaQ4WlLacpdNeV1xRLC0oNZgFpblZQpJqYkF1meUjqcEsqElk8UiaABZUW1g6kjrGgmqo649Y0XfPoXXE0KRaE+UVf6664khuqjvCvFlQkjSB2lhI/SwoqYOW/c3/BeDetyytOYlGaRJKqZcFJXXQHtd+H7CgJsWkFdM0C0qSWmRSy2gmFpQkNVCXimg2FpQkNYCF9HgWlNRBj2y/qO4IwlIaxIKSOmjdx55Vd4ROspDmZ6u6A0hSF1hO8+cWlNRB+77zXgC+8bZlteaYVJbRaFhQUgftfuNDgAU1SpbS6FVeUBGxCFgLfDszj656PEkaJ4upOuPYgvoT4CvALmMYS5IqZymNR6UHSUTEXsDvARdXOY4kjcOR3GQ5jVHVW1DnAn8O7DzbChGxClgFsHSp84JJ4/Dw7tvUHaHRLKFmqKygIuJo4HuZuS4iVsy2XmauBlYDTE1NeVY+aQzWX/XMuiM0jqXUPFVuQT0fODYijgK2A3aJiA9l5kkVjilJ82IxNVdlBZWZZwBnAJRbUG+xnKRm2P+MewC4+6/2qTlJPSyldvB7UFIH7XrLj+qOMDaWUXuNpaAycw2wZhxjSRJYTJPAufgkTRzLaTK4i09S61lIk8mCkjroF3ttW3eEBbGQusGCkjpow4cOrDvCvFhI3WRBSaqV5aPZDCyocjbyN2fmOWPII2kMnnHq1wD46rn7jX1sC0nDGlhQmflIRLwUsKCkCbHL+p+MZRzLSAsx7C6+z0bE3wGXAz+dvjMzv1BJKkmtYhGpCsMW1CHl8h099yXwotHGkdQ0lo/qMlRBZeahVQeR9HjVlcOKil9fWrihCioingycDfxGZr4kIg4EDs7Mf6g0XYe9h7+oO4Ia4D1cX8nrnrb/9gC8r6LXH6ebOLLuCKrIsLv4LgUuAd5a3r6b4vMoC0pqofet/pO6I8ybRdQ9wxbU4sy8IiLOAMjMTRHxSIW5JHWURaRpwxbUTyNid4oDI4iI3wK6M1+/NGFOW3UeUP+WlGWkuQxbUH8KXAPsGxGfBZYAL68slaRK7XX3t2sb21LSsIYtqC8DLwQOAAK4C0/VIWkeLCbN17AFdUtmPoeiqACIiC8Az6kklaSJYClpIeYsqIh4CvBUYPuIOIhi6wlgF2CHirNJahkLSaM0aAvqxcBKYC/gfWwuqB8DZ1YXS1KVvr58n5G8joWkKs1ZUJl5GXBZRByXmVeNKZOkip1/7uuHXtcSUl2G/Qxqr4jYhWLL6f0Unz2dnpk3VJZMUm0sJTXBsAX1msw8LyJeDOwBvJpiZgkLSmqJx5TOSScVyw99qJ4w0hCGLajpz56OAi7JzDsiIuZ6gqTxmtdWz8aN1QWRRmTYgloXETcATwfOiIidgV/P9YSI2A64Gdi2HOfKzHz7QsJK2szdcJp0wxbUa4HlwD2Z+bNy2qNXD3jOL4EXZeZPImIb4DMR8bHMvHUBeaXOsIDUdcMW1G+Xy2cNu2cvMxOYPq/0NuUl55VO6hALSXqsYQvqz3qubwc8F1jHgDPqRsSicr1/BZyfmZ+fYZ1VwCqApUuXDhlHapfGlc/BB9edQBooig2deT4pYm/gvZn5iiHX3xW4GnhTZn5ptvWmpqZy7dq1884ziQ6dgBPJdVnjCklqsIhYl5lT/fcPuwXVbyPwzGFXzswfRsQa4Ehg1oKS2sgykqox7Cnf/yubPz/aiuKAiTsGPGcJ8KuynLYHDgfes4CsUq0mqoiOO65YXuUEMWquYbegeve7bQI+kpmfHfCcPSmmSVpEUWpXZOa1W5BRGquJKqLZfP/7dSeQBhqqoMo5+eYlMzcAB807kTRmnSgkqYUGnW7ji8xxaHhmPmvkiaSKWERSuwzagvp94MnAfX33Pw24v5JE0gJZRNJkGFRQ5wBnZua3eu8sD4A4BzimqmBSP4tnhA47rO4E0kCDCmpZ+VnSY2Tm2ohYVkkidZYFNEZve1vdCaSBBhXUdnM8tv0og6gbLCFJwxpUULdFxB9l5vt774yI11JMYaSOs3Ba6iUvKZYf+1i9OaQ5DCqoU4GrI+IP2VxIU8ATgH9XZTDVy+KZcD//ed0JpIHmLKjM/C5wSEQcyuapjf53Zn6q8mQaC4tIUlMN+0Xdm4CbKs6iMbCQJLXFlk4Wq4aziCS1nQXVApaNRu7oo+tOIA1kQTXUmg9vLqXhzmEszcNvvKVYfrjeGPORr6w7gcbNgpJUK4tHs7GgpA666V0rADj0rDW1jG8paRgWlKTKWERaCAtK0hazgFQlC0rSUCwjjZsFJWlGFpLqZkFJHXTF8/7gcfdZSGoaC0rqoAsueUOxrDmHNJfKCioi9gb+EXgK8GtgdWaeV9V4kub2mC2kn/2sWO6wQy1ZpGFUuQW1CTgtM78QETsD6yLiE5l5Z4VjSmKI3XVHHVUs16ypOoq0xSorqMz8DvCd8vqPI+IrwFMBC0oaIT870qQay2dQEbEMOAj4/AyPrQJWASxdunQccaTWsYTURZUXVETsBFwFnJqZ/9L/eGauBlYDTE1NZdV5pKayhKTHqrSgImIbinL6p8z871WOJbWFRSQNp8qj+AL4B+Armfm3VY0jNVljy2jlyroTSANVuQX1fOBk4IsRsb6878zMvK7CMaWxa2wJzcWCUgtUeRTfZ/Bce2qxVhbPsB58sFguXlxvDmkOziShiTbRJbMQxx9fLP0elBrMglKrWUDS5LKg1HiWkNRNFpQqYalIWigLSnOyaCTVxYLqEMtGjzrllLoTSANZUE31xtG/ZFTwmmqrE4qFPaUtlD+ofgwLSuqgvX59HwAbt9q75iRqm3EU0zQLSuqgD/70ZAAO3XlNvUHUeOMspH4WlCTpUXUWUj8LSpI6rEmF1M+CkqQOanIxTbOgJKlD2lBM0ywoqYPet+1pdUfQmLWpmKZZUFIHXfuEY+qOoDFoYyn1sqCkDtr/kbsAuHvRATUn0ai0vYxmYkFJHXTRz14H+D2otpvEUuplQUlSy0x6MU3bqqoXjogPRMT3IuJLVY0hSV2SP+hOOUGFBQVcChxZ4etLUid0rZimVbaLLzNvjohlVb2+JE26LpZSLz+DkjroXdudVXcEzaLrpdSr9oKKiFXAKoClS5fWnEbqhhu3ObzuCOpjMT1elZ9BDSUzV2fmVGZOLVmypO44Uic8e9N6nr1pfd0xOm/6syXLaWa1b0FJGr9zf34q4Peg6mAZDa/Kw8w/AtwCHBARGyPitVWNJUlN55bS/FV5FN8rqnptSWo6y2jh3MUnSSNgIY2eBSVJ82QZjYcFJXXQmdufXXeEVrGQ6mFBSR10y9aH1B2hESyeZrOgpA46eNPngMkuKsun/SwoqYPO/vmZQLu/B2UBTT4LStLYWS4ahgUlaV4sF42LBSV11IrnQ66pO4U0OwtKarkt2qJZMeoU0uhZUE310F/WnUAtETH/5zybZwBwR/hzVpfMt9cdofEsKKmD7mDPuiN0imW0ZSwoqYMO4xsA3Mi+NSeZXJbSwllQUgedxc2ABTVqltJoWVCSNE8W0XhYUJI0gIVUDwtKknpYRs1hQUnqPEupmSwoqYNexzF1R2gMy6m5LCipg+5mcd0RamEZtYsFJXXQ0dwFwLUcUHOS6lhG7VdpQUXEkcB5wCLg4sx8d5XjSRrOaRQnLGxbQVk63VJZQUXEIuB84HeBjcBtEXFNZt5Z1ZiS2sXC0Vyq3IJ6LvD1zLwHICI+CrwUsKCkDrGEtKWqLKinAvf13N4IPK9/pYhYBawCWLp0aYVxJFXNMtIoVVlQM50EIB93R+ZqYDXA1NTU4x6X1AyWj8atyoLaCOzdc3sv4P4Kx5M0pJP5/UevWzxqqioL6jZgv4h4OvBt4ETglRWOJ2kGFpDaqrKCysxNEfFG4OMUh5l/IDO/XNV4UpcsuHQuv7xYnnDCwsNIFan0e1CZeR1wXZVjSJOo8q2eCy8slhaUGsyZJKSauOtNmpsFJVXMIpK2jAUlLZAFJFXDgpKGZBFJ42VBST06U0JXXll3AmkgC0qd1Jkims3ibp4PSu1iQWkidb6ABrn00mK5cmWdKaQ5WVBqJAumYhaUWsCCUuUsG0lbwoJqKP9Rl9R1W9UdQJKkmVhQkqRGchef1EXXOYezms+Ckrpohx3qTiAN5C4+qYsuuKC4SA1mQUlddMUVxUVqMAtKktRIFpQkqZEsKElSI1lQkqRGisysO8OjIuIB4FsVDrEYeLDC1x+ltmRtS04waxXakhPMWoVR5XxaZi7pv7NRBVW1iFibmVN15xhGW7K2JSeYtQptyQlmrULVOd3FJ0lqJAtKktRIXSuo1XUHmIe2ZG1LTjBrFdqSE8xahUpzduozKElSe3RtC0qS1BIWlCSpkSa6oCLiSRHxiYj4WrncbZb1ro+IH0bEtWPOd2RE3BURX4+I02d4fNuIuLx8/PMRsWyc+fqyDMr6OxHxhYjYFBHH15GxJ8ugrH8aEXdGxIaIuDEintbQnK+PiC9GxPqI+ExEHFhHzjLLnFl71js+IjIiajtEeoj3dWVEPFC+r+sj4j80MWe5zh+UP6tfjogPjztjT45B7+k5Pe/n3RHxw5EMnJkTewHeC5xeXj8deM8s6x0GHANcO8Zsi4BvAPsATwDuAA7sW+cNwN+X108ELq/pfRwm6zLgWcA/AsfX+Hc+TNZDgR3K66fU8b4OmXOXnuvHAtc39T0t19sZuBm4FZhqalZgJfB3deSbZ879gNuB3crbezQ1a9/6bwI+MIqxJ3oLCngpcFl5/TLgZTOtlJk3Aj8eV6jSc4GvZ+Y9mfkw8FGKvL16818JHBYRMcaM0wZmzcx7M3MD8Osa8vUaJutNmfmz8uatwF5jzgjD5fyXnps7AnUd0TTMzyrAOyn+U/iLcYbrM2zWug2T84+A8zPzIYDM/N6YM06b73v6CuAjoxh40gvqyZn5HYByuUfNeXo9Fbiv5/bG8r4Z18nMTcCPgN3Hkm6WHKWZsjbFfLO+FvhYpYlmNlTOiPjjiPgGxT/8bx5Ttn4Ds0bEQcDemTnW3eQzGPbv/7hyF++VEbH3eKI9xjA59wf2j4jPRsStEXHk2NI91tC/U+Xu8qcDnxrFwK0/5XtEfBJ4ygwPvXXcWeZppi2h/v8hD7POODQlxzCGzhoRJwFTwAsrTTSzoXJm5vnA+RHxSuAs4FVVB5vBnFkjYivgHIpdZ3Ub5n39X8BHMvOXEfF6ir0UL6o82WMNk3Nrit18Kyi28j8dEc/MzNF8vjO8+fz+nwhcmZmPjGLg1hdUZh4+22MR8d2I2DMzvxMRewJ1bSLPZCPQ+z+3vYD7Z1lnY0RsDTwR+MF44s2YY9pMWZtiqKwRcTjFf2JemJm/HFO2XvN9Tz8KXFhpotkNyroz8ExgTbkH+inANRFxbGauHVvKwsD3NTO/33Pz/cB7xpCr37C//7dm5q+Ab0bEXRSFddt4Ij4mx7A/qycCfzyqgSd9F981bP4f56uA/1ljln63AftFxNMj4gkUf7HX9K3Tm/944FNZfgo5ZsNkbYqBWcvdURcBx9a4X3+YnPv13Pw94GtjzNdrzqyZ+aPMXJyZyzJzGcXnenWU08CsAOV/VqcdC3xljPmmDfM79T8oDughIhZT7PK7Z6wpC0P9/kfEAcBuwC0jG7mOo0LGePTJ7sCNFL/YNwJPKu+fAi7uWe/TwAPAzyn+t/DiMeU7Crib4giZt5b3vYPilxtgO+C/AV8H/hnYp8b3clDWf1u+dz8Fvg98ucFZPwl8F1hfXq5paM7zgC+XGW8C/k1T39O+dddQ01F8Q76vf1W+r3eU7+szGpozgL8F7gS+CJzY1Pe0vP2fgHePclynOpIkNdKk7+KTJLWUBSVJaiQLSpLUSBaUJKmRLChJUiNZUGqliHhrOcPzhnIG5eeV9188Pet3RNwbEYsjYllEfKniPMvK2R6mby+PiKOqHHOOLEuimP3+9oh4QUS8PCK+EhE3RcRURPyXAc+/LiJ23cKxX1bnrOuaLK2fSULdExEHA0cDz8liuprFFLMsk5m1nDqBYjb3VwLTp0RYTvF9u+tqyHIY8NXMfBUUp5MB3pCZN5WPz/kF2sxcSLG+DLiW4rs70oK4BaU22hN4MMspijLzwcy8HyAi1sxyLqJFEfH+cqvrhojYvlx/eTkR54aIuDrKc4b1vk65FXZveX1RRPx1RNxWPud15eu/G3hBuTX3FxRfYjyhvH1CROwYER8on3d7RMw4G3RE/HkU54C6IyLePSDjvlGcy2xdRHw6Ip4REcspJpY9qhz77cBvA39f5l4R5XnPImKniLikHG9DRBxX3n9vWfpExEkR8c/la10UEYvK+38SEf+5zHlrRDw5Ig6hmJnhr8v1993Cv1+pUNc3k7142dILsBPF7Ap3AxdQzKc3/dgaylkMgHuBxRRbN5uA5eX9VwAnldc3TD+folTOneF1FgP3ltdXAWeV17el2Bp5OsWEntf25FhJzzmHgLN7xty1zL5j35/rJcDn2HyuqicNyHgjsF95/XkUU2HNNHbvn+XRnBRz0J3bs95ufe/bv6aYWHWb8v4LgH9fXk/gmPL6e3vek0up8XxgXibr4i4+tU5m/iQifhN4AcVcZZdHxOmZeekcT/tmZq4vr68DlkXEE4FdM/P/lPdfRjG11FyOAJ4Vm88a/ESKCTwfHuJ5x0bEW8rb2wFLeew8cIcDl2R5rqrM/MFsGSNiJ+CQ8vr087cdkKHf4RTzqlGO91Df44cBvwncVo6xPZsnXH6YYlceFO/n785zbGkgC0qtlMV0/msoZtD+IsWkupfO8ZTeGcsfofjHdi6b2LwLfLue+wN4U2Z+vHfliFgx4PUCOC4z7xqwzrBzj20F/DAzlw+5/paMF8BlmXnGDI/9KjOnn/sI/luiCvgZlFonIg7om+l7OfCt+b5OZv4IeCgiXlDedTIwvaVyL8XWAxQzyU/7OHBKRGxTZtk/InakOCPzzj3r9d/+OPCmKDdFophRvd8NwGsiYodynSfNljGLs+1+MyJeXq4bEfHseb0BxXhvnL4x/dlWjxuB4yNij+k8UZyQbi79f25pi1lQaqOdgMsi4s6I2AAcSDGT8pZ4FcWH+hsoiu4d5f1/Q1FEn6P4PGbaxRRHqH2hPHT9Ioqthw3ApvKggf9IMUv2gdMHSVCcDn0bYEP5vHf2B8nM6ylOY7A2ItYD07sDZ8v4h8BrI+IOitm553tq83cBu0XEl8rXOLQvz50UJ0m8oRz7ExQHqMzlo8CflQeCeJCEFsTZzCVJjeQWlCSpkSwoSVIjWVCSpEayoCRJjWRBSZIayYKSJDWSBSVJaqT/D9MvTD5TNmFPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(reducedDT, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6107955063694607\n"
     ]
    }
   ],
   "source": [
    "print(completeness_score(y,clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6091364049733291\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y,clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Compare these results with those obtained on the full data in part b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are eerily similar, which is pretty incredible considering we just ditched 12 dimensions. In fact, the mean of the silhouettes is actually slightly higher with PCA, probably due to not overfitting the extraneous dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Item-Based Joke Recommendation [Dataset: jokes.zip]__\n",
    "\n",
    "For this problem you will use a modified version of the item-based recommender algorithm from Ch. 14 of Machine Learning in Action and use it on joke ratings data based on Jester Online Joke Recommender System. \n",
    "\n",
    "The modified version of the code is provided in the module itemBasedRec.py. \n",
    "\n",
    "Most of the module will be used as is, but you will add some additional functionality.\n",
    "\n",
    "The data set contains two files. The file \"modified_jester_data.csv\" contains the ratings on 100 jokes by 1000 users (each row is a user profile). \n",
    "\n",
    "The ratings have been normalized to be between 1 and 21 (a 20-point scale), with 1 being the lowest rating. A zero indicated a missing rating. The file \"jokes.csv\" contains the joke ids mapped to the actual text of the jokes.\n",
    "\n",
    "Your tasks in this problem are the following (please also see comments for the function stubs in the provided module):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Load in the joke ratings data and the joke text data into appropriate data structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/claytoncohn/Dropbox/New/DePaul/DSC478/data/jokes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.18</td>\n",
       "      <td>19.79</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.17</td>\n",
       "      <td>2.02</td>\n",
       "      <td>6.24</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.08</td>\n",
       "      <td>10.71</td>\n",
       "      <td>17.36</td>\n",
       "      <td>15.37</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.34</td>\n",
       "      <td>10.27</td>\n",
       "      <td>5.66</td>\n",
       "      <td>19.88</td>\n",
       "      <td>20.22</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.71</td>\n",
       "      <td>18.86</td>\n",
       "      <td>10.81</td>\n",
       "      <td>8.86</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>19.16</td>\n",
       "      <td>8.18</td>\n",
       "      <td>17.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.50</td>\n",
       "      <td>15.61</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.61</td>\n",
       "      <td>12.36</td>\n",
       "      <td>12.60</td>\n",
       "      <td>18.04</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.56</td>\n",
       "      <td>16.73</td>\n",
       "      <td>...</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.58</td>\n",
       "      <td>15.27</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.73</td>\n",
       "      <td>12.55</td>\n",
       "      <td>14.11</td>\n",
       "      <td>17.55</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.46</td>\n",
       "      <td>11.44</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.91</td>\n",
       "      <td>6.68</td>\n",
       "      <td>2.31</td>\n",
       "      <td>10.13</td>\n",
       "      <td>4.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>...</td>\n",
       "      <td>7.46</td>\n",
       "      <td>4.11</td>\n",
       "      <td>10.32</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.82</td>\n",
       "      <td>7.65</td>\n",
       "      <td>11.05</td>\n",
       "      <td>1.92</td>\n",
       "      <td>5.95</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.59</td>\n",
       "      <td>1.15</td>\n",
       "      <td>18.72</td>\n",
       "      <td>19.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.84</td>\n",
       "      <td>14.16</td>\n",
       "      <td>20.17</td>\n",
       "      <td>4.79</td>\n",
       "      <td>2.84</td>\n",
       "      <td>9.30</td>\n",
       "      <td>20.27</td>\n",
       "      <td>12.41</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.58</td>\n",
       "      <td>...</td>\n",
       "      <td>18.23</td>\n",
       "      <td>9.88</td>\n",
       "      <td>10.90</td>\n",
       "      <td>5.32</td>\n",
       "      <td>7.84</td>\n",
       "      <td>7.65</td>\n",
       "      <td>13.14</td>\n",
       "      <td>10.95</td>\n",
       "      <td>12.31</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.21</td>\n",
       "      <td>7.46</td>\n",
       "      <td>1.58</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.26</td>\n",
       "      <td>10.71</td>\n",
       "      <td>5.71</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.14</td>\n",
       "      <td>9.40</td>\n",
       "      <td>...</td>\n",
       "      <td>15.37</td>\n",
       "      <td>10.71</td>\n",
       "      <td>15.17</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.01</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.15</td>\n",
       "      <td>14.01</td>\n",
       "      <td>17.41</td>\n",
       "      <td>16.15</td>\n",
       "      <td>19.93</td>\n",
       "      <td>13.52</td>\n",
       "      <td>14.01</td>\n",
       "      <td>19.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9   ...    90  \\\n",
       "0  3.18 19.79  1.34  2.84  3.48  2.50  1.15 15.17  2.02  6.24  ... 13.82   \n",
       "1 15.08 10.71 17.36 15.37  8.62  1.34 10.27  5.66 19.88 20.22  ... 13.82   \n",
       "2  0.00  0.00  0.00  0.00 20.03 20.27 20.03 20.27  0.00  0.00  ...  0.00   \n",
       "3  0.00 19.35  0.00  0.00 12.80 19.16  8.18 17.21  0.00 12.84  ...  0.00   \n",
       "4 19.50 15.61  6.83  5.61 12.36 12.60 18.04 15.61 10.56 16.73  ... 16.19   \n",
       "5  4.83  7.46 11.44  2.50  3.91  6.68  2.31 10.13  4.35  9.20  ...  7.46   \n",
       "6  0.00  0.00  0.00  0.00 19.59  1.15 18.72 19.79  0.00  0.00  ...  0.00   \n",
       "7 17.84 14.16 20.17  4.79  2.84  9.30 20.27 12.41  5.81  6.58  ... 18.23   \n",
       "8  7.21  7.46  1.58  4.11  2.26 10.71  5.71  2.07  3.14  9.40  ... 15.37   \n",
       "9 14.01 16.15 16.15 14.01 17.41 16.15 19.93 13.52 14.01 19.16  ...  0.00   \n",
       "\n",
       "     91    92    93    94    95    96    97    98    99  \n",
       "0  0.00  0.00  0.00  0.00  0.00  5.37  0.00  0.00  0.00  \n",
       "1  6.05 10.71 18.86 10.81  8.86 14.06 11.34  6.68 12.07  \n",
       "2  0.00  0.00 20.08  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "3  0.00  0.00 11.53  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "4 16.58 15.27 16.19 16.73 12.55 14.11 17.55 12.80 12.60  \n",
       "5  4.11 10.32  8.04  8.82  7.65 11.05  1.92  5.95  7.55  \n",
       "6  0.00  0.00  0.00  0.00 13.33  0.00  0.00  0.00  0.00  \n",
       "7  9.88 10.90  5.32  7.84  7.65 13.14 10.95 12.31 11.00  \n",
       "8 10.71 15.17 10.71 10.71 10.71 10.71 10.71  7.60  6.05  \n",
       "9 15.47  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(DATA_PATH + \"modified_jester_data.csv\", header=None)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.18</td>\n",
       "      <td>19.79</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.17</td>\n",
       "      <td>2.02</td>\n",
       "      <td>6.24</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.08</td>\n",
       "      <td>10.71</td>\n",
       "      <td>17.36</td>\n",
       "      <td>15.37</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.34</td>\n",
       "      <td>10.27</td>\n",
       "      <td>5.66</td>\n",
       "      <td>19.88</td>\n",
       "      <td>20.22</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.71</td>\n",
       "      <td>18.86</td>\n",
       "      <td>10.81</td>\n",
       "      <td>8.86</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.82</td>\n",
       "      <td>9.51</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.76</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>6.62</td>\n",
       "      <td>10.14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5.02</td>\n",
       "      <td>20.08</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.82</td>\n",
       "      <td>19.35</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.76</td>\n",
       "      <td>12.80</td>\n",
       "      <td>19.16</td>\n",
       "      <td>8.18</td>\n",
       "      <td>17.21</td>\n",
       "      <td>6.62</td>\n",
       "      <td>12.84</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5.02</td>\n",
       "      <td>11.53</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.50</td>\n",
       "      <td>15.61</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.61</td>\n",
       "      <td>12.36</td>\n",
       "      <td>12.60</td>\n",
       "      <td>18.04</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.56</td>\n",
       "      <td>16.73</td>\n",
       "      <td>...</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.58</td>\n",
       "      <td>15.27</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.73</td>\n",
       "      <td>12.55</td>\n",
       "      <td>14.11</td>\n",
       "      <td>17.55</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.46</td>\n",
       "      <td>11.44</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.91</td>\n",
       "      <td>6.68</td>\n",
       "      <td>2.31</td>\n",
       "      <td>10.13</td>\n",
       "      <td>4.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>...</td>\n",
       "      <td>7.46</td>\n",
       "      <td>4.11</td>\n",
       "      <td>10.32</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.82</td>\n",
       "      <td>7.65</td>\n",
       "      <td>11.05</td>\n",
       "      <td>1.92</td>\n",
       "      <td>5.95</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.82</td>\n",
       "      <td>9.51</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.76</td>\n",
       "      <td>19.59</td>\n",
       "      <td>1.15</td>\n",
       "      <td>18.72</td>\n",
       "      <td>19.79</td>\n",
       "      <td>6.62</td>\n",
       "      <td>10.14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.47</td>\n",
       "      <td>13.33</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.84</td>\n",
       "      <td>14.16</td>\n",
       "      <td>20.17</td>\n",
       "      <td>4.79</td>\n",
       "      <td>2.84</td>\n",
       "      <td>9.30</td>\n",
       "      <td>20.27</td>\n",
       "      <td>12.41</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.58</td>\n",
       "      <td>...</td>\n",
       "      <td>18.23</td>\n",
       "      <td>9.88</td>\n",
       "      <td>10.90</td>\n",
       "      <td>5.32</td>\n",
       "      <td>7.84</td>\n",
       "      <td>7.65</td>\n",
       "      <td>13.14</td>\n",
       "      <td>10.95</td>\n",
       "      <td>12.31</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.21</td>\n",
       "      <td>7.46</td>\n",
       "      <td>1.58</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.26</td>\n",
       "      <td>10.71</td>\n",
       "      <td>5.71</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.14</td>\n",
       "      <td>9.40</td>\n",
       "      <td>...</td>\n",
       "      <td>15.37</td>\n",
       "      <td>10.71</td>\n",
       "      <td>15.17</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.01</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.15</td>\n",
       "      <td>14.01</td>\n",
       "      <td>17.41</td>\n",
       "      <td>16.15</td>\n",
       "      <td>19.93</td>\n",
       "      <td>13.52</td>\n",
       "      <td>14.01</td>\n",
       "      <td>19.16</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>15.47</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.09</td>\n",
       "      <td>15.08</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.27</td>\n",
       "      <td>9.40</td>\n",
       "      <td>13.48</td>\n",
       "      <td>5.71</td>\n",
       "      <td>6.62</td>\n",
       "      <td>12.46</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>17.17</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.31</td>\n",
       "      <td>12.80</td>\n",
       "      <td>13.57</td>\n",
       "      <td>8.62</td>\n",
       "      <td>11.73</td>\n",
       "      <td>11.73</td>\n",
       "      <td>10.03</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.77</td>\n",
       "      <td>9.64</td>\n",
       "      <td>...</td>\n",
       "      <td>12.46</td>\n",
       "      <td>12.70</td>\n",
       "      <td>11.29</td>\n",
       "      <td>7.70</td>\n",
       "      <td>14.45</td>\n",
       "      <td>16.44</td>\n",
       "      <td>15.08</td>\n",
       "      <td>13.48</td>\n",
       "      <td>15.51</td>\n",
       "      <td>15.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.82</td>\n",
       "      <td>9.51</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.76</td>\n",
       "      <td>16.87</td>\n",
       "      <td>9.40</td>\n",
       "      <td>16.58</td>\n",
       "      <td>11.53</td>\n",
       "      <td>6.62</td>\n",
       "      <td>18.14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.40</td>\n",
       "      <td>18.52</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.22</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.22</td>\n",
       "      <td>19.30</td>\n",
       "      <td>18.43</td>\n",
       "      <td>11.44</td>\n",
       "      <td>14.50</td>\n",
       "      <td>19.16</td>\n",
       "      <td>16.97</td>\n",
       "      <td>19.98</td>\n",
       "      <td>...</td>\n",
       "      <td>19.11</td>\n",
       "      <td>9.98</td>\n",
       "      <td>16.58</td>\n",
       "      <td>17.84</td>\n",
       "      <td>16.53</td>\n",
       "      <td>5.08</td>\n",
       "      <td>19.20</td>\n",
       "      <td>19.98</td>\n",
       "      <td>2.84</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.79</td>\n",
       "      <td>5.22</td>\n",
       "      <td>17.02</td>\n",
       "      <td>14.69</td>\n",
       "      <td>18.77</td>\n",
       "      <td>5.17</td>\n",
       "      <td>19.69</td>\n",
       "      <td>19.59</td>\n",
       "      <td>5.08</td>\n",
       "      <td>18.52</td>\n",
       "      <td>...</td>\n",
       "      <td>13.72</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.41</td>\n",
       "      <td>19.69</td>\n",
       "      <td>2.26</td>\n",
       "      <td>7.99</td>\n",
       "      <td>19.30</td>\n",
       "      <td>6.19</td>\n",
       "      <td>8.62</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.50</td>\n",
       "      <td>12.55</td>\n",
       "      <td>13.33</td>\n",
       "      <td>6.87</td>\n",
       "      <td>15.22</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.04</td>\n",
       "      <td>10.51</td>\n",
       "      <td>13.91</td>\n",
       "      <td>12.99</td>\n",
       "      <td>...</td>\n",
       "      <td>14.11</td>\n",
       "      <td>12.70</td>\n",
       "      <td>11.24</td>\n",
       "      <td>5.08</td>\n",
       "      <td>18.28</td>\n",
       "      <td>9.64</td>\n",
       "      <td>14.74</td>\n",
       "      <td>13.82</td>\n",
       "      <td>8.14</td>\n",
       "      <td>14.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.82</td>\n",
       "      <td>1.73</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.62</td>\n",
       "      <td>9.40</td>\n",
       "      <td>19.74</td>\n",
       "      <td>4.69</td>\n",
       "      <td>6.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.16</td>\n",
       "      <td>18.62</td>\n",
       "      <td>14.79</td>\n",
       "      <td>19.25</td>\n",
       "      <td>15.22</td>\n",
       "      <td>18.62</td>\n",
       "      <td>13.43</td>\n",
       "      <td>11.97</td>\n",
       "      <td>11.53</td>\n",
       "      <td>11.83</td>\n",
       "      <td>...</td>\n",
       "      <td>11.83</td>\n",
       "      <td>16.68</td>\n",
       "      <td>14.69</td>\n",
       "      <td>11.19</td>\n",
       "      <td>11.29</td>\n",
       "      <td>14.59</td>\n",
       "      <td>11.49</td>\n",
       "      <td>19.06</td>\n",
       "      <td>11.49</td>\n",
       "      <td>18.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.22</td>\n",
       "      <td>14.64</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.76</td>\n",
       "      <td>13.52</td>\n",
       "      <td>9.40</td>\n",
       "      <td>15.13</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.62</td>\n",
       "      <td>18.91</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>11.05</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>12.65</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.82</td>\n",
       "      <td>18.62</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.76</td>\n",
       "      <td>2.36</td>\n",
       "      <td>13.43</td>\n",
       "      <td>19.93</td>\n",
       "      <td>4.40</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.53</td>\n",
       "      <td>...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9   ...    90  \\\n",
       "0   3.18 19.79  1.34  2.84  3.48  2.50  1.15 15.17  2.02  6.24  ... 13.82   \n",
       "1  15.08 10.71 17.36 15.37  8.62  1.34 10.27  5.66 19.88 20.22  ... 13.82   \n",
       "2   8.82  9.51  7.65  5.76 20.03 20.27 20.03 20.27  6.62 10.14  ...  4.67   \n",
       "3   8.82 19.35  7.65  5.76 12.80 19.16  8.18 17.21  6.62 12.84  ...  4.67   \n",
       "4  19.50 15.61  6.83  5.61 12.36 12.60 18.04 15.61 10.56 16.73  ... 16.19   \n",
       "5   4.83  7.46 11.44  2.50  3.91  6.68  2.31 10.13  4.35  9.20  ...  7.46   \n",
       "6   8.82  9.51  7.65  5.76 19.59  1.15 18.72 19.79  6.62 10.14  ...  4.67   \n",
       "7  17.84 14.16 20.17  4.79  2.84  9.30 20.27 12.41  5.81  6.58  ... 18.23   \n",
       "8   7.21  7.46  1.58  4.11  2.26 10.71  5.71  2.07  3.14  9.40  ... 15.37   \n",
       "9  14.01 16.15 16.15 14.01 17.41 16.15 19.93 13.52 14.01 19.16  ...  4.67   \n",
       "10  8.09 15.08  7.65  5.76  5.27  9.40 13.48  5.71  6.62 12.46  ...  4.67   \n",
       "11 12.31 12.80 13.57  8.62 11.73 11.73 10.03 16.00  3.77  9.64  ... 12.46   \n",
       "12  8.82  9.51  7.65  5.76 16.87  9.40 16.58 11.53  6.62 18.14  ...  4.67   \n",
       "13 20.22 20.27 20.22 19.30 18.43 11.44 14.50 19.16 16.97 19.98  ... 19.11   \n",
       "14 19.79  5.22 17.02 14.69 18.77  5.17 19.69 19.59  5.08 18.52  ... 13.72   \n",
       "15  7.50 12.55 13.33  6.87 15.22  8.72  8.04 10.51 13.91 12.99  ... 14.11   \n",
       "16  8.82  1.73  7.65  5.76  3.62  9.40 19.74  4.69  6.62 13.33  ...  4.67   \n",
       "17 14.16 18.62 14.79 19.25 15.22 18.62 13.43 11.97 11.53 11.83  ... 11.83   \n",
       "18 15.22 14.64  7.65  5.76 13.52  9.40 15.13  5.81  6.62 18.91  ...  4.67   \n",
       "19  8.82 18.62  7.65  5.76  2.36 13.43 19.93  4.40  6.62  1.53  ...  4.67   \n",
       "\n",
       "      91    92    93    94    95    96    97    98    99  \n",
       "0   4.40  5.02  4.46  4.47  4.70  5.37  4.32  4.52  4.34  \n",
       "1   6.05 10.71 18.86 10.81  8.86 14.06 11.34  6.68 12.07  \n",
       "2   4.40  5.02 20.08  4.47  4.70  4.84  4.32  4.52  4.34  \n",
       "3   4.40  5.02 11.53  4.47  4.70  4.84  4.32  4.52  4.34  \n",
       "4  16.58 15.27 16.19 16.73 12.55 14.11 17.55 12.80 12.60  \n",
       "5   4.11 10.32  8.04  8.82  7.65 11.05  1.92  5.95  7.55  \n",
       "6   4.40  5.02  4.46  4.47 13.33  4.84  4.32  4.52  4.34  \n",
       "7   9.88 10.90  5.32  7.84  7.65 13.14 10.95 12.31 11.00  \n",
       "8  10.71 15.17 10.71 10.71 10.71 10.71 10.71  7.60  6.05  \n",
       "9  15.47  5.02  4.46  4.47  4.70  4.84  4.32  4.52  4.34  \n",
       "10 17.17  5.02  4.46  4.47  4.70  4.84  4.32  4.52  4.34  \n",
       "11 12.70 11.29  7.70 14.45 16.44 15.08 13.48 15.51 15.66  \n",
       "12  4.40 18.52  4.46  4.47  4.70  4.84  4.32  4.52  4.34  \n",
       "13  9.98 16.58 17.84 16.53  5.08 19.20 19.98  2.84 17.50  \n",
       "14  5.51  2.41 19.69  2.26  7.99 19.30  6.19  8.62  5.03  \n",
       "15 12.70 11.24  5.08 18.28  9.64 14.74 13.82  8.14 14.45  \n",
       "16  4.40  5.02  4.46  4.47  4.70  4.84  4.32  4.52  4.34  \n",
       "17 16.68 14.69 11.19 11.29 14.59 11.49 19.06 11.49 18.62  \n",
       "18 11.05  5.02  4.46  4.47  4.70 12.65  4.32  4.52  4.34  \n",
       "19  4.40  5.02  4.46  4.47  4.70  4.84  4.32  4.52  4.34  \n",
       "\n",
       "[20 rows x 100 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 0s (no rating) with column mean\n",
    "X_replace = X.mask(X==0).fillna(X.mean())\n",
    "X_replace.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A man visits the doctor. The doctor says \"I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This couple had an excellent relationship goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q. What's 200 feet long and has 4 teeth? A. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Q. What's the difference between a man and a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Q. What's O. J. Simpson's Internet address? A....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill &amp; Hillary are on a trip back to Arkansas....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>How many feminists does it take to screw in a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Q. Did you hear about the dyslexic devil worsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A country guy goes into a city bar that has a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Two cannibals are eating a clown one turns to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0  A man visits the doctor. The doctor says \"I ha...\n",
       "1  1  This couple had an excellent relationship goin...\n",
       "2  2  Q. What's 200 feet long and has 4 teeth? A. Th...\n",
       "3  3  Q. What's the difference between a man and a t...\n",
       "4  4  Q. What's O. J. Simpson's Internet address? A....\n",
       "5  5  Bill & Hillary are on a trip back to Arkansas....\n",
       "6  6  How many feminists does it take to screw in a ...\n",
       "7  7  Q. Did you hear about the dyslexic devil worsh...\n",
       "8  8  A country guy goes into a city bar that has a ...\n",
       "9  9  Two cannibals are eating a clown one turns to ..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(DATA_PATH + \"jokes.csv\", header=None)\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Use the \"recommend\" function to provide top 5 joke recommendations for at least 2 users. \n",
    "    \n",
    "    Use both standard item-based collaborative filtering (based on the rating prediction function \"standEst\") and \n",
    "    the SVD-based version of the item-based CF (using \"svdEst\" as the prediction engine) to generate these \n",
    "    recommendations for the two users and note the differences. \n",
    "    \n",
    "    You should show the text of the recommended jokes as well as the predicted ratings for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
