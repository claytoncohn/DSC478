{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clayton Cohn<br>\n",
    "May 20, 2020<br>\n",
    "DSC 478<br>\n",
    "Prof. Mobasher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"/Users/claytoncohn/Dropbox/New/DePaul/DSC478/data/segmentation_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will experiment with Principal Component Analysis as a dimensionality reduction approach to assist in clustering high-dimensional data. \n",
    "\n",
    "You will also experiment with item-based recommendation for a joke recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. PCA for Reduced Dimensionality in Clustering [Dataset: segmentation_data.zip]__\n",
    "\n",
    "For this problem you will use an image segmentation data set for clustering. \n",
    "\n",
    "You will experiment with using PCA as an approach to reduce dimensionality and noise in the data. \n",
    "\n",
    "You will compare the results of clustering the data with and without PCA using the provided image class assignments as the ground truth. \n",
    "\n",
    "The data set is divided into three files. The file \"segmentation_data.txt\" contains data about images with each line corresponding to one image. \n",
    "\n",
    "Each image is represented by 19 features (these are the columns in the data and correspond to the feature names in the file \"segmentation_names.txt\". \n",
    "\n",
    "The file \"segmentation_classes.txt\" contains the class labels (the type of image) and a numeric class label for each of the corresponding images in the data file. \n",
    "\n",
    "After clustering the image data, you will use the class labels to measure completeness and homogeneity of the generated clusters. \n",
    "\n",
    "The data set used in this problem is based on the Image Segmentation data set at the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Load in the image data matrix (with rows as images and columns as features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1.186342</td>\n",
       "      <td>12.925926</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>-6.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>17.222221</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>0.508139</td>\n",
       "      <td>1.910864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.720082</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.750309</td>\n",
       "      <td>13.740741</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>-6.222222</td>\n",
       "      <td>-10.222222</td>\n",
       "      <td>16.444445</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>0.463329</td>\n",
       "      <td>1.941465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>2.195113</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.520234</td>\n",
       "      <td>12.259259</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>9.333334</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>-5.777778</td>\n",
       "      <td>-8.777778</td>\n",
       "      <td>14.555555</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>0.480149</td>\n",
       "      <td>1.987902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>1.254621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>12.703704</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>16.222221</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>1.875362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.005540</td>\n",
       "      <td>15.592592</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>11.777778</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.444445</td>\n",
       "      <td>16.555555</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>1.863654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.646930</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.620633</td>\n",
       "      <td>12.111111</td>\n",
       "      <td>10.222222</td>\n",
       "      <td>8.111112</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-5.666666</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>17.666666</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>1.877146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944445</td>\n",
       "      <td>1.083547</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.632993</td>\n",
       "      <td>14.629630</td>\n",
       "      <td>13.222222</td>\n",
       "      <td>11.444445</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>-4.222222</td>\n",
       "      <td>-9.555555</td>\n",
       "      <td>13.777778</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>0.408965</td>\n",
       "      <td>1.860191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611111</td>\n",
       "      <td>0.646930</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>1.722401</td>\n",
       "      <td>15.296296</td>\n",
       "      <td>14.777778</td>\n",
       "      <td>12.888889</td>\n",
       "      <td>18.222221</td>\n",
       "      <td>-1.555556</td>\n",
       "      <td>-7.222222</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>18.222221</td>\n",
       "      <td>0.312227</td>\n",
       "      <td>1.783512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>2.146487</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>1.327766</td>\n",
       "      <td>14.481482</td>\n",
       "      <td>12.555555</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>19.555555</td>\n",
       "      <td>-5.777778</td>\n",
       "      <td>-9.444445</td>\n",
       "      <td>15.222222</td>\n",
       "      <td>19.555555</td>\n",
       "      <td>0.422174</td>\n",
       "      <td>1.950405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>1.985130</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>1.614747</td>\n",
       "      <td>13.703704</td>\n",
       "      <td>11.222222</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>18.777779</td>\n",
       "      <td>-7.444445</td>\n",
       "      <td>-7.777778</td>\n",
       "      <td>15.222222</td>\n",
       "      <td>18.777779</td>\n",
       "      <td>0.439852</td>\n",
       "      <td>2.099904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1   2         3    4         5         6         7         8   \\\n",
       "0  110.0  189.0   9  0.000000  0.0  1.000000  0.666667  1.222222  1.186342   \n",
       "1   86.0  187.0   9  0.000000  0.0  1.111111  0.720082  1.444444  0.750309   \n",
       "2  225.0  244.0   9  0.000000  0.0  3.388889  2.195113  3.000000  1.520234   \n",
       "3   47.0  232.0   9  0.000000  0.0  1.277778  1.254621  1.000000  0.894427   \n",
       "4   97.0  186.0   9  0.000000  0.0  1.166667  0.691215  1.166667  1.005540   \n",
       "5  157.0  221.0   9  0.000000  0.0  1.055556  0.646930  1.222222  0.620633   \n",
       "6   62.0  224.0   9  0.000000  0.0  0.944445  1.083547  2.333333  1.632993   \n",
       "7   27.0  248.0   9  0.111111  0.0  1.611111  0.646930  3.166667  1.722401   \n",
       "8   44.0  233.0   9  0.000000  0.0  2.222222  2.146487  2.111111  1.327766   \n",
       "9   17.0  229.0   9  0.000000  0.0  2.111111  1.985130  2.444445  1.614747   \n",
       "\n",
       "          9          10         11         12        13         14         15  \\\n",
       "0  12.925926  10.888889   9.222222  18.666668 -6.111111 -11.111111  17.222221   \n",
       "1  13.740741  11.666667  10.333334  19.222221 -6.222222 -10.222222  16.444445   \n",
       "2  12.259259  10.333334   9.333334  17.111110 -5.777778  -8.777778  14.555555   \n",
       "3  12.703704  11.000000   9.000000  18.111110 -5.111111 -11.111111  16.222221   \n",
       "4  15.592592  13.888889  11.777778  21.111110 -5.111111 -11.444445  16.555555   \n",
       "5  12.111111  10.222222   8.111112  18.000000 -5.666666 -12.000000  17.666666   \n",
       "6  14.629630  13.222222  11.444445  19.222221 -4.222222  -9.555555  13.777778   \n",
       "7  15.296296  14.777778  12.888889  18.222221 -1.555556  -7.222222   8.777778   \n",
       "8  14.481482  12.555555  11.333333  19.555555 -5.777778  -9.444445  15.222222   \n",
       "9  13.703704  11.222222  11.111111  18.777779 -7.444445  -7.777778  15.222222   \n",
       "\n",
       "          16        17        18  \n",
       "0  18.666668  0.508139  1.910864  \n",
       "1  19.222221  0.463329  1.941465  \n",
       "2  17.111110  0.480149  1.987902  \n",
       "3  18.111110  0.500966  1.875362  \n",
       "4  21.111110  0.442661  1.863654  \n",
       "5  18.000000  0.549180  1.877146  \n",
       "6  19.222221  0.408965  1.860191  \n",
       "7  18.222221  0.312227  1.783512  \n",
       "8  19.555555  0.422174  1.950405  \n",
       "9  18.777779  0.439852  2.099904  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(DATA_PATH + \"segmentation_data.txt\", header=None)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Also load in the numeric class labels from the segmentation class file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(DATA_PATH + \"segmentation_classes.txt\", header=None, sep=\"\\t\").iloc[:, 1]\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REGION-CENTROID-COL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REGION-CENTROID-ROW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REGION-PIXEL-COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHORT-LINE-DENSITY-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHORT-LINE-DENSITY-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "0   REGION-CENTROID-COL\n",
       "1   REGION-CENTROID-ROW\n",
       "2    REGION-PIXEL-COUNT\n",
       "3  SHORT-LINE-DENSITY-5\n",
       "4  SHORT-LINE-DENSITY-2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv(DATA_PATH + \"segmentation_names.txt\", header=None, sep=\"\\t\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using your favorite method (e.g., sklearn's min-max scaler), perform min-max normalization on the data matrix\n",
    "    so that each feature is scaled to [0,1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.30830040e-01, 7.41666667e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.42205474e-02, 6.72233922e-04, 2.73291926e-02,\n",
       "        8.55743510e-04, 9.01110284e-02, 7.94165331e-02, 6.11192912e-02,\n",
       "        1.30943107e-01, 7.31343290e-01, 1.41176540e-02, 8.72865267e-01,\n",
       "        1.23711348e-01, 5.08138840e-01, 8.31849232e-01],\n",
       "       [3.35968379e-01, 7.33333333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.80228046e-02, 7.26095734e-04, 3.22981359e-02,\n",
       "        5.41219947e-04, 9.57913810e-02, 8.50891441e-02, 6.84830672e-02,\n",
       "        1.34840205e-01, 7.29477615e-01, 2.35294199e-02, 8.59582565e-01,\n",
       "        1.27393216e-01, 4.63329080e-01, 8.36986460e-01],\n",
       "       [8.85375494e-01, 9.70833333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.15969577e-01, 2.21344355e-03, 6.70807367e-02,\n",
       "        1.09658970e-03, 8.54634659e-02, 7.53646732e-02, 6.18556741e-02,\n",
       "        1.20031165e-01, 7.36940304e-01, 3.88235327e-02, 8.27324481e-01,\n",
       "        1.13402054e-01, 4.80149030e-01, 8.44782328e-01],\n",
       "       [1.81818182e-01, 9.20833333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.37262383e-02, 1.26509804e-03, 2.23602471e-02,\n",
       "        6.45176713e-04, 8.85618432e-02, 8.02269050e-02, 5.96465386e-02,\n",
       "        1.27045974e-01, 7.48134334e-01, 1.41176540e-02, 8.55787468e-01,\n",
       "        1.20029447e-01, 5.00965950e-01, 8.25889142e-01],\n",
       "       [3.79446640e-01, 7.29166667e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.99239709e-02, 6.96986866e-04, 2.60869646e-02,\n",
       "        7.25325858e-04, 1.08701264e-01, 1.01296598e-01, 7.80559656e-02,\n",
       "        1.48090401e-01, 7.48134334e-01, 1.05882352e-02, 8.61480079e-01,\n",
       "        1.39911626e-01, 4.42660570e-01, 8.23923576e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_norm = scaler.fit_transform(X)\n",
    "X_norm[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Using the Kmeans implementation in scikit-learn, perform clustering on the image data (use K = 7 in your \n",
    "    clustering so that later we can compare the clusters to the 7 pre-assigned image classes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KMeans code taken from lecture notebook\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Can only use Euclidean distance with sklearn KMeans\n",
    "kmeans = KMeans(n_clusters=7,max_iter=1000,verbose=0)\n",
    "kmeans.fit(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 6, 6, 6, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       2, 6, 6, 6, 6, 2, 6, 2, 6, 2, 6, 6, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6,\n",
       "       6, 6, 6, 6, 2, 2, 6, 6, 2, 6, 6, 6, 6, 6, 6, 2, 2, 2, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 2, 2, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 6,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 2, 2,\n",
       "       2, 3, 3, 2, 6, 2, 3, 2, 3, 6, 3, 2, 2, 2, 2, 2, 3, 6, 2, 6, 3, 6,\n",
       "       3, 6, 6, 6, 6, 2, 2, 6, 6, 3, 3, 2, 3, 6, 2, 2, 2, 3, 2, 3, 2, 3,\n",
       "       6, 2, 3, 2, 6, 3, 2, 2, 2, 3, 6, 2, 2, 2, 2, 2, 3, 2, 6, 6, 2, 6,\n",
       "       3, 6, 2, 3, 2, 2, 2, 6, 2, 2, 2, 6, 6, 2, 2, 6, 2, 2, 2, 2, 3, 2,\n",
       "       6, 6, 6, 2, 2, 2, 2, 2, 6, 2, 3, 3, 3, 3, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = kmeans.predict(X)\n",
    "clusters[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Print the cluster centroids (use some formatting so that they are visually understandable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(REGION-CENTROID-COL,)</th>\n",
       "      <th>(REGION-CENTROID-ROW,)</th>\n",
       "      <th>(REGION-PIXEL-COUNT,)</th>\n",
       "      <th>(SHORT-LINE-DENSITY-5,)</th>\n",
       "      <th>(SHORT-LINE-DENSITY-2,)</th>\n",
       "      <th>(VEDGE-MEAN,)</th>\n",
       "      <th>(VEDGE-SD,)</th>\n",
       "      <th>(HEDGE-MEAN,)</th>\n",
       "      <th>(HEDGE-SD,)</th>\n",
       "      <th>(INTENSITY-MEAN,)</th>\n",
       "      <th>(RAWRED-MEAN,)</th>\n",
       "      <th>(RAWBLUE-MEAN,)</th>\n",
       "      <th>(RAWGREEN-MEAN,)</th>\n",
       "      <th>(EXRED-MEAN,)</th>\n",
       "      <th>(EXBLUE-MEAN,)</th>\n",
       "      <th>(EXGREEN-MEAN,)</th>\n",
       "      <th>(VALUE-MEAN,)</th>\n",
       "      <th>(SATURATION-MEAN,)</th>\n",
       "      <th>(HUE-MEAN,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (REGION-CENTROID-COL,)  (REGION-CENTROID-ROW,)  (REGION-PIXEL-COUNT,)  \\\n",
       "0                    0.30                    0.53                   0.00   \n",
       "1                    0.25                    0.46                   0.00   \n",
       "2                    0.51                    0.81                   0.00   \n",
       "3                    0.54                    0.15                   0.00   \n",
       "4                    0.77                    0.43                   0.00   \n",
       "5                    0.25                    0.39                   0.00   \n",
       "6                    0.75                    0.53                   0.00   \n",
       "\n",
       "   (SHORT-LINE-DENSITY-5,)  (SHORT-LINE-DENSITY-2,)  (VEDGE-MEAN,)  \\\n",
       "0                     0.05                     0.05           0.10   \n",
       "1                     0.03                     0.01           0.04   \n",
       "2                     0.08                     0.01           0.05   \n",
       "3                     0.03                     0.00           0.03   \n",
       "4                     0.01                     0.02           0.04   \n",
       "5                     0.08                     0.02           0.08   \n",
       "6                     0.04                     0.04           0.11   \n",
       "\n",
       "   (VEDGE-SD,)  (HEDGE-MEAN,)  (HEDGE-SD,)  (INTENSITY-MEAN,)  (RAWRED-MEAN,)  \\\n",
       "0         0.01           0.08         0.01               0.40            0.37   \n",
       "1         0.00           0.03         0.00               0.03            0.02   \n",
       "2         0.00           0.05         0.00               0.11            0.09   \n",
       "3         0.00           0.03         0.00               0.82            0.78   \n",
       "4         0.00           0.02         0.00               0.04            0.03   \n",
       "5         0.00           0.06         0.01               0.15            0.14   \n",
       "6         0.02           0.11         0.02               0.30            0.28   \n",
       "\n",
       "   (RAWBLUE-MEAN,)  (RAWGREEN-MEAN,)  (EXRED-MEAN,)  (EXBLUE-MEAN,)  \\\n",
       "0             0.47              0.35           0.50            0.57   \n",
       "1             0.04              0.02           0.77            0.22   \n",
       "2             0.09              0.14           0.68            0.08   \n",
       "3             0.89              0.79           0.27            0.67   \n",
       "4             0.06              0.03           0.78            0.22   \n",
       "5             0.18              0.12           0.72            0.34   \n",
       "6             0.35              0.26           0.59            0.45   \n",
       "\n",
       "   (EXGREEN-MEAN,)  (VALUE-MEAN,)  (SATURATION-MEAN,)  (HUE-MEAN,)  \n",
       "0             0.21           0.47                0.30         0.16  \n",
       "1             0.51           0.04                0.80         0.18  \n",
       "2             0.82           0.13                0.41         0.89  \n",
       "3             0.29           0.89                0.21         0.13  \n",
       "4             0.49           0.06                0.54         0.24  \n",
       "5             0.35           0.18                0.41         0.20  \n",
       "6             0.31           0.35                0.30         0.16  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format='{:,.2f}'.format\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=features)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    To evaluate your clusters, first perform Silhouette analysis on the clusters (compute Silhouette values for all \n",
    "    instances in the data, and then compute the overall mean Silhouette value; optionally, you can provide a \n",
    "    visaulization of the Silhouettes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29557484  0.31970635  0.11400406  0.28454809  0.30673754  0.23471905\n",
      "  0.28272014  0.15970701  0.26682125  0.23066837  0.26184245  0.25035792\n",
      "  0.26346504  0.32038677  0.06744948  0.30254298  0.24174827  0.20845443\n",
      " -0.02450426 -0.05844824]\n"
     ]
    }
   ],
   "source": [
    "# Silhouette analysis code taken from lecture notebooks\n",
    "from sklearn import metrics\n",
    "\n",
    "silhouettes = metrics.silhouette_samples(X_norm, clusters)\n",
    "print(silhouettes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05254510983783871\n"
     ]
    }
   ],
   "source": [
    "print(silhouettes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import pylab as pl\n",
    "\n",
    "def plot_silhouettes(data, clusters, metric='euclidean'):\n",
    "    \n",
    "    from matplotlib import cm\n",
    "    from sklearn.metrics import silhouette_samples\n",
    "\n",
    "    cluster_labels = np.unique(clusters)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = metrics.silhouette_samples(data, clusters, metric='euclidean')\n",
    "    c_ax_lower, c_ax_upper = 0, 0\n",
    "    cticks = []\n",
    "    for i, k in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[clusters == k]\n",
    "        c_silhouette_vals.sort()\n",
    "        c_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        pl.barh(range(c_ax_lower, c_ax_upper), c_silhouette_vals, height=1.0, \n",
    "                      edgecolor='none', color=color)\n",
    "\n",
    "        cticks.append((c_ax_lower + c_ax_upper) / 2)\n",
    "        c_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    pl.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n",
    "\n",
    "    pl.yticks(cticks, cluster_labels)\n",
    "    pl.ylabel('Cluster')\n",
    "    pl.xlabel('Silhouette coefficient')\n",
    "\n",
    "    pl.tight_layout()\n",
    "    #pl.savefig('images/11_04.png', dpi=300)\n",
    "    pl.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(X_norm, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Next, compare your 7 clusters to the 7 pre-assigned classes by computing the Completeness and Homogeneity \n",
    "    values of the generated clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.422413881877115\n"
     ]
    }
   ],
   "source": [
    "# Code for homogeneity and completeness taken from lecture notebooks\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "print(completeness_score(y,clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2313098656272253\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity_score(y,clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    c. Perform PCA on the normalized image data matrix. \n",
    "    \n",
    "    You may use the linear algebra package in Numpy or the Decomposition module in scikit-learn (the latter is much more efficient). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08  0.    0.   -0.   -0.   -0.    0.   -0.    0.    0.    0.    0.01  0.01 -0.01  0.    0.\n",
      "   0.01 -0.01  0.  ]\n",
      " [ 0.    0.06  0.    0.    0.    0.   -0.    0.   -0.   -0.03 -0.03 -0.03 -0.03  0.02 -0.02  0.02\n",
      "  -0.03  0.    0.04]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.  ]\n",
      " [-0.    0.    0.    0.02 -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.   -0.    0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.    0.    0.   -0.    0.01  0.    0.    0.    0.   -0.   -0.   -0.   -0.   -0.    0.   -0.\n",
      "  -0.    0.   -0.  ]\n",
      " [-0.    0.    0.   -0.    0.    0.01  0.    0.    0.   -0.   -0.    0.   -0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.    0.   -0.    0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.\n",
      "   0.    0.   -0.  ]\n",
      " [-0.    0.    0.   -0.    0.    0.    0.    0.01  0.    0.    0.    0.    0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.    0.   -0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.03  0.   -0.   -0.   -0.   -0.    0.    0.    0.07  0.07  0.08  0.07 -0.04  0.04 -0.03\n",
      "   0.08 -0.04 -0.02]\n",
      " [ 0.   -0.03  0.   -0.   -0.   -0.   -0.    0.    0.    0.07  0.07  0.07  0.06 -0.04  0.04 -0.03\n",
      "   0.07 -0.04 -0.02]\n",
      " [ 0.01 -0.03  0.   -0.   -0.    0.    0.    0.    0.    0.08  0.07  0.08  0.07 -0.05  0.05 -0.03\n",
      "   0.08 -0.04 -0.03]\n",
      " [ 0.01 -0.03  0.   -0.   -0.   -0.    0.    0.    0.    0.07  0.06  0.07  0.06 -0.04  0.04 -0.02\n",
      "   0.07 -0.04 -0.02]\n",
      " [-0.01  0.02  0.    0.   -0.   -0.   -0.   -0.   -0.   -0.04 -0.04 -0.05 -0.04  0.04 -0.03  0.02\n",
      "  -0.05  0.02  0.01]\n",
      " [ 0.   -0.02  0.   -0.    0.    0.    0.    0.    0.    0.04  0.04  0.05  0.04 -0.03  0.04 -0.03\n",
      "   0.05 -0.02 -0.03]\n",
      " [ 0.    0.02  0.    0.   -0.   -0.    0.   -0.   -0.   -0.03 -0.03 -0.03 -0.02  0.02 -0.03  0.04\n",
      "  -0.03  0.01  0.04]\n",
      " [ 0.01 -0.03  0.   -0.   -0.    0.    0.    0.    0.    0.08  0.07  0.08  0.07 -0.05  0.05 -0.03\n",
      "   0.08 -0.04 -0.03]\n",
      " [-0.01  0.    0.   -0.    0.   -0.    0.   -0.   -0.   -0.04 -0.04 -0.04 -0.04  0.02 -0.02  0.01\n",
      "  -0.04  0.05 -0.  ]\n",
      " [ 0.    0.04  0.    0.   -0.   -0.   -0.   -0.   -0.   -0.02 -0.02 -0.03 -0.02  0.01 -0.03  0.04\n",
      "  -0.03 -0.    0.07]]\n"
     ]
    }
   ],
   "source": [
    "# PCA code taken from lecture notebooks\n",
    "from sklearn import decomposition\n",
    "\n",
    "meanVals = np.mean(X_norm, axis=0)\n",
    "meanRemoved = X_norm - meanVals #remove mean\n",
    "covMat = np.cov(meanRemoved, rowvar=0)\n",
    "\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "print(covMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:  [0.48 0.1  0.08 0.04 0.03 0.02 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "Eigenvectors: [[ 0.03 -0.35  0.93  0.04 -0.01  0.03  0.01  0.03 -0.   -0.02 -0.01  0.01 -0.    0.    0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.19 -0.38 -0.12 -0.66 -0.47  0.14 -0.24  0.22  0.06  0.07  0.06 -0.04 -0.01 -0.01  0.    0.\n",
      "  -0.   -0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.  ]\n",
      " [-0.01 -0.03 -0.04 -0.03  0.06  0.6   0.72  0.32  0.06  0.08  0.01 -0.01 -0.   -0.    0.    0.\n",
      "   0.    0.    0.  ]\n",
      " [-0.    0.02  0.01 -0.1  -0.09 -0.44  0.28  0.32 -0.77  0.05  0.07 -0.    0.01  0.   -0.   -0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.    0.02  0.01 -0.12 -0.03 -0.42  0.3   0.11  0.44 -0.34  0.55  0.28 -0.11 -0.01 -0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [ 0.    0.01  0.01 -0.01 -0.01 -0.18  0.12  0.07  0.18 -0.14  0.05 -0.77  0.55  0.01 -0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.01  0.   -0.   -0.14 -0.03 -0.33  0.19  0.16  0.29 -0.02 -0.77  0.29  0.21 -0.01 -0.   -0.\n",
      "   0.   -0.    0.  ]\n",
      " [ 0.    0.    0.   -0.02 -0.01 -0.16  0.09  0.07  0.13 -0.05 -0.24 -0.49 -0.8   0.01  0.   -0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.38 -0.11 -0.06  0.09 -0.05  0.02 -0.08  0.16  0.01 -0.05  0.    0.   -0.   -0.21  0.74 -0.02\n",
      "   0.11  0.36  0.  ]\n",
      " [ 0.36 -0.11 -0.07  0.09  0.01  0.04 -0.13  0.24  0.   -0.11 -0.    0.01 -0.   -0.21 -0.06  0.5\n",
      "  -0.62  0.1   0.  ]\n",
      " [ 0.41 -0.07 -0.04  0.03 -0.08  0.03 -0.04  0.07 -0.01 -0.06 -0.01 -0.   -0.   -0.22 -0.16 -0.81\n",
      "  -0.16 -0.08  0.  ]\n",
      " [ 0.36 -0.16 -0.08  0.14 -0.06 -0.01 -0.08  0.18  0.04  0.02  0.02  0.   -0.   -0.21 -0.53  0.27\n",
      "   0.69 -0.39  0.  ]\n",
      " [-0.24  0.06  0.    0.01  0.39  0.13 -0.31  0.5  -0.05 -0.42 -0.04  0.03 -0.    0.08 -0.2  -0.11\n",
      "  -0.06  0.37  0.  ]\n",
      " [ 0.26  0.18  0.08 -0.27 -0.18  0.04  0.18 -0.4  -0.08 -0.08 -0.04 -0.02  0.   -0.08 -0.3   0.1\n",
      "  -0.2   0.62  0.  ]\n",
      " [-0.18 -0.34 -0.13  0.43 -0.11 -0.2   0.03  0.14  0.17  0.55  0.1   0.    0.    0.05 -0.13 -0.08\n",
      "  -0.24  0.43  0.  ]\n",
      " [ 0.41 -0.1  -0.06  0.04 -0.1   0.02 -0.03  0.06 -0.   -0.07 -0.01  0.02  0.    0.89 -0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.2   0.31  0.08  0.42 -0.74  0.12 -0.03  0.13 -0.01 -0.3  -0.06  0.03  0.   -0.01 -0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [-0.17 -0.64 -0.24  0.2   0.01  0.02  0.18 -0.35 -0.18 -0.5  -0.12  0.02  0.   -0.04 -0.    0.\n",
      "  -0.   -0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as la\n",
    "eigVals,eigVects = la.eig(np.mat(covMat))\n",
    "print(\"Eigenvalues: \",eigVals)\n",
    "print(\"Eigenvectors:\",eigVects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48 0.1  0.08 0.04 0.03 0.02 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "[60.71 13.2  10.12  4.54  3.55  1.99  1.89  1.62  1.07  0.71  0.39  0.16  0.05  0.    0.    0.\n",
      "  0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "eigValInd = np.argsort(eigVals)  #sort, sort goes smallest to largest\n",
    "eigValInd = eigValInd[::-1]   #reverse\n",
    "sortedEigVals = eigVals[eigValInd]\n",
    "print(sortedEigVals)\n",
    "total = sum(sortedEigVals)\n",
    "varPercentage = sortedEigVals/total*100\n",
    "print(varPercentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Analyze the principal components to determine the number, r, of PCs needed to capture at least 95% of variance in the data.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PCs: 60.714233968533236\n",
      "2 PCs: 73.91121320168925\n",
      "3 PCs: 84.03498614256189\n",
      "4 PCs: 88.57852534332582\n",
      "5 PCs: 92.12588648109565\n",
      "6 PCs: 94.1139219796062\n",
      "7 PCs: 96.00589227704954\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(10):\n",
    "    total += varPercentage[i]\n",
    "    print(\"{} PCs: {}\".format(i+1, total))\n",
    "    if total >= 95: break\n",
    "        \n",
    "topNfeat = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows us that we will need 7 principal compents to capture 95% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Provide a plot of PC variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1, 11), varPercentage[:10], marker='^')\n",
    "plt.xlabel('Principal Component Number')\n",
    "plt.ylabel('Percentage of Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Then use these r components as features to transform the data into a reduced dimension space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69 -0.53 -0.25 ... -0.08 -0.05 -0.05]\n",
      " [-0.67 -0.51 -0.34 ... -0.04 -0.06 -0.04]\n",
      " [-0.71 -0.77  0.16 ... -0.17 -0.04 -0.06]\n",
      " ...\n",
      " [-0.51  0.13  0.08 ... -0.03  0.03 -0.11]\n",
      " [-0.48  0.09  0.16 ...  0.    0.   -0.09]\n",
      " [-0.44  0.11  0.05 ...  0.02  0.21  0.15]]\n"
     ]
    }
   ],
   "source": [
    "topEigValInd = eigValInd[:topNfeat]  #cut off unwanted dimensions\n",
    "reducedEigVects = eigVects[:,topEigValInd]   #reorganize eig vects largest to smallest\n",
    "reducedDT = np.dot(meanRemoved, reducedEigVects)    #transform data into new dimensions\n",
    "print(reducedDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
